{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "object_map = {0: \"bicycle\", 1: \"bus\", 2: \"crosswalk\", 3: \"pedestrian\", 4: \"pedestrian sign\", 5: \"stop sign\", 6: \"tactile paving\", 7: \"traffic light\", 8: \"truck\", 9: \"car\", 10: \"scooter\", 11: \"motorcycle\"}\n",
    "object_list = list(object_map.values())\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "output_embeddings = []\n",
    "for obj in object_list:\n",
    "    encoded_input = tokenizer(obj, return_tensors='tf')\n",
    "    output = model(encoded_input)\n",
    "    output_embeddings.append(torch.Tensor(output.last_hidden_state.numpy().sum(axis=1).squeeze(0)))\n",
    "    \n",
    "file_name = 'vocab_embeddings.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(output_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "try:\n",
    "    with open('vocab_embeddings.pkl', 'rb') as file:\n",
    "        output_embeddings = pickle.load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"The file was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = 'sgg_data.csv'\n",
    "features = []\n",
    "images = []\n",
    "labels = []\n",
    "with open(csv_file, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        images.append(row[0])\n",
    "        labels.append(int(row[-1]))\n",
    "        bb1 = [float(item) for item in row[1:5]]\n",
    "        bb2 = [float(item) for item in row[6:10]]\n",
    "        diff_bb = [float(bb1[i]) - float(bb2[i]) for i in range(len(bb1))]\n",
    "        features.append([int(row[5])] + bb1 + [int(row[10])] + bb2 + diff_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = []\n",
    "for i in range(len(features)):\n",
    "    X.append(torch.cat((torch.Tensor(features[i]), output_embeddings[features[i][0]], output_embeddings[features[i][5]], output_embeddings[features[i][0]] - output_embeddings[features[i][5]])))\n",
    "X = torch.stack(X)\n",
    "Y = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "u1k--jLDzNO8"
   },
   "outputs": [],
   "source": [
    "from SceneGraph import SceneGraph\n",
    "def create_model(num_classes, num_features):\n",
    "    model = SceneGraph(num_classes, num_features)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8KgjEKkTzS_7"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, features, labels):\n",
    "    model.train()\n",
    "\n",
    "    features, labels = Variable(features), Variable(labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(features)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yOvVcBhfzV6a"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, features, labels):\n",
    "    model.eval()\n",
    "\n",
    "    features, labels = Variable(features), Variable(labels)\n",
    "\n",
    "    outputs = model(features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total = labels.size(0)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KHfGN5WWzZcs"
   },
   "outputs": [],
   "source": [
    "model = create_model(num_classes=16, num_features=X.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NaTqtlirzceM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 | Training Loss: 0.7524 | Validation Loss: 3.4944\n",
      "Epoch: 2/1000 | Training Loss: 0.7326 | Validation Loss: 3.4910\n",
      "Epoch: 3/1000 | Training Loss: 0.7326 | Validation Loss: 3.4977\n",
      "Epoch: 4/1000 | Training Loss: 0.7341 | Validation Loss: 3.4961\n",
      "Epoch: 5/1000 | Training Loss: 0.7356 | Validation Loss: 3.4786\n",
      "Epoch: 6/1000 | Training Loss: 0.7429 | Validation Loss: 3.5306\n",
      "Epoch: 7/1000 | Training Loss: 0.7565 | Validation Loss: 3.5333\n",
      "Epoch: 8/1000 | Training Loss: 0.7689 | Validation Loss: 3.5109\n",
      "Epoch: 9/1000 | Training Loss: 0.7745 | Validation Loss: 3.5585\n",
      "Epoch: 10/1000 | Training Loss: 0.7765 | Validation Loss: 3.4747\n",
      "Epoch: 11/1000 | Training Loss: 0.7446 | Validation Loss: 3.4738\n",
      "Epoch: 12/1000 | Training Loss: 0.7233 | Validation Loss: 3.5708\n",
      "Epoch: 13/1000 | Training Loss: 0.7361 | Validation Loss: 3.5184\n",
      "Epoch: 14/1000 | Training Loss: 0.7644 | Validation Loss: 3.5830\n",
      "Epoch: 15/1000 | Training Loss: 0.7757 | Validation Loss: 3.5402\n",
      "Epoch: 16/1000 | Training Loss: 0.7677 | Validation Loss: 3.5044\n",
      "Epoch: 17/1000 | Training Loss: 0.7534 | Validation Loss: 3.5979\n",
      "Epoch: 18/1000 | Training Loss: 0.7396 | Validation Loss: 3.5022\n",
      "Epoch: 19/1000 | Training Loss: 0.7301 | Validation Loss: 3.5328\n",
      "Epoch: 20/1000 | Training Loss: 0.7430 | Validation Loss: 3.5468\n",
      "Epoch: 21/1000 | Training Loss: 0.7548 | Validation Loss: 3.5198\n",
      "Epoch: 22/1000 | Training Loss: 0.7517 | Validation Loss: 3.5612\n",
      "Epoch: 23/1000 | Training Loss: 0.7460 | Validation Loss: 3.5170\n",
      "Epoch: 24/1000 | Training Loss: 0.7424 | Validation Loss: 3.5652\n",
      "Epoch: 25/1000 | Training Loss: 0.7286 | Validation Loss: 3.5128\n",
      "Epoch: 26/1000 | Training Loss: 0.7134 | Validation Loss: 3.5494\n",
      "Epoch: 27/1000 | Training Loss: 0.7277 | Validation Loss: 3.5908\n",
      "Epoch: 28/1000 | Training Loss: 0.7448 | Validation Loss: 3.5597\n",
      "Epoch: 29/1000 | Training Loss: 0.7609 | Validation Loss: 3.5741\n",
      "Epoch: 30/1000 | Training Loss: 0.7678 | Validation Loss: 3.5890\n",
      "Epoch: 31/1000 | Training Loss: 0.7643 | Validation Loss: 3.5919\n",
      "Epoch: 32/1000 | Training Loss: 0.7448 | Validation Loss: 3.5922\n",
      "Epoch: 33/1000 | Training Loss: 0.7190 | Validation Loss: 3.5284\n",
      "Epoch: 34/1000 | Training Loss: 0.7285 | Validation Loss: 3.6608\n",
      "Epoch: 35/1000 | Training Loss: 0.7663 | Validation Loss: 3.5874\n",
      "Epoch: 36/1000 | Training Loss: 0.7690 | Validation Loss: 3.5463\n",
      "Epoch: 37/1000 | Training Loss: 0.7596 | Validation Loss: 3.6310\n",
      "Epoch: 38/1000 | Training Loss: 0.7545 | Validation Loss: 3.5419\n",
      "Epoch: 39/1000 | Training Loss: 0.7434 | Validation Loss: 3.6113\n",
      "Epoch: 40/1000 | Training Loss: 0.7270 | Validation Loss: 3.5681\n",
      "Epoch: 41/1000 | Training Loss: 0.7476 | Validation Loss: 3.5458\n",
      "Epoch: 42/1000 | Training Loss: 0.7631 | Validation Loss: 3.6287\n",
      "Epoch: 43/1000 | Training Loss: 0.7650 | Validation Loss: 3.5182\n",
      "Epoch: 44/1000 | Training Loss: 0.7395 | Validation Loss: 3.6080\n",
      "Epoch: 45/1000 | Training Loss: 0.7253 | Validation Loss: 3.6470\n",
      "Epoch: 46/1000 | Training Loss: 0.7338 | Validation Loss: 3.5640\n",
      "Epoch: 47/1000 | Training Loss: 0.7448 | Validation Loss: 3.6033\n",
      "Epoch: 48/1000 | Training Loss: 0.7537 | Validation Loss: 3.5619\n",
      "Epoch: 49/1000 | Training Loss: 0.7474 | Validation Loss: 3.5897\n",
      "Epoch: 50/1000 | Training Loss: 0.7158 | Validation Loss: 3.6214\n",
      "Epoch: 51/1000 | Training Loss: 0.7097 | Validation Loss: 3.6011\n",
      "Epoch: 52/1000 | Training Loss: 0.7258 | Validation Loss: 3.6369\n",
      "Epoch: 53/1000 | Training Loss: 0.7301 | Validation Loss: 3.5660\n",
      "Epoch: 54/1000 | Training Loss: 0.7233 | Validation Loss: 3.5823\n",
      "Epoch: 55/1000 | Training Loss: 0.7189 | Validation Loss: 3.6141\n",
      "Epoch: 56/1000 | Training Loss: 0.7091 | Validation Loss: 3.5762\n",
      "Epoch: 57/1000 | Training Loss: 0.7048 | Validation Loss: 3.6282\n",
      "Epoch: 58/1000 | Training Loss: 0.7031 | Validation Loss: 3.6036\n",
      "Epoch: 59/1000 | Training Loss: 0.7097 | Validation Loss: 3.6060\n",
      "Epoch: 60/1000 | Training Loss: 0.7203 | Validation Loss: 3.5692\n",
      "Epoch: 61/1000 | Training Loss: 0.7210 | Validation Loss: 3.6320\n",
      "Epoch: 62/1000 | Training Loss: 0.7206 | Validation Loss: 3.6126\n",
      "Epoch: 63/1000 | Training Loss: 0.7321 | Validation Loss: 3.6647\n",
      "Epoch: 64/1000 | Training Loss: 0.7431 | Validation Loss: 3.7003\n",
      "Epoch: 65/1000 | Training Loss: 0.7437 | Validation Loss: 3.6021\n",
      "Epoch: 66/1000 | Training Loss: 0.7409 | Validation Loss: 3.6969\n",
      "Epoch: 67/1000 | Training Loss: 0.7383 | Validation Loss: 3.5976\n",
      "Epoch: 68/1000 | Training Loss: 0.7385 | Validation Loss: 3.6960\n",
      "Epoch: 69/1000 | Training Loss: 0.7094 | Validation Loss: 3.6722\n",
      "Epoch: 70/1000 | Training Loss: 0.7170 | Validation Loss: 3.6211\n",
      "Epoch: 71/1000 | Training Loss: 0.7556 | Validation Loss: 3.7040\n",
      "Epoch: 72/1000 | Training Loss: 0.7452 | Validation Loss: 3.6866\n",
      "Epoch: 73/1000 | Training Loss: 0.7960 | Validation Loss: 3.6887\n",
      "Epoch: 74/1000 | Training Loss: 0.8139 | Validation Loss: 3.6763\n",
      "Epoch: 75/1000 | Training Loss: 0.7392 | Validation Loss: 3.7597\n",
      "Epoch: 76/1000 | Training Loss: 0.8059 | Validation Loss: 3.6765\n",
      "Epoch: 77/1000 | Training Loss: 0.7420 | Validation Loss: 3.6174\n",
      "Epoch: 78/1000 | Training Loss: 0.7826 | Validation Loss: 3.7687\n",
      "Epoch: 79/1000 | Training Loss: 0.7770 | Validation Loss: 3.6641\n",
      "Epoch: 80/1000 | Training Loss: 0.7396 | Validation Loss: 3.6009\n",
      "Epoch: 81/1000 | Training Loss: 0.7452 | Validation Loss: 3.7004\n",
      "Epoch: 82/1000 | Training Loss: 0.7231 | Validation Loss: 3.7387\n",
      "Epoch: 83/1000 | Training Loss: 0.7346 | Validation Loss: 3.6529\n",
      "Epoch: 84/1000 | Training Loss: 0.7291 | Validation Loss: 3.6757\n",
      "Epoch: 85/1000 | Training Loss: 0.7438 | Validation Loss: 3.7080\n",
      "Epoch: 86/1000 | Training Loss: 0.7465 | Validation Loss: 3.7137\n",
      "Epoch: 87/1000 | Training Loss: 0.7345 | Validation Loss: 3.6178\n",
      "Epoch: 88/1000 | Training Loss: 0.7365 | Validation Loss: 3.7590\n",
      "Epoch: 89/1000 | Training Loss: 0.7240 | Validation Loss: 3.6923\n",
      "Epoch: 90/1000 | Training Loss: 0.7067 | Validation Loss: 3.6240\n",
      "Epoch: 91/1000 | Training Loss: 0.7124 | Validation Loss: 3.7695\n",
      "Epoch: 92/1000 | Training Loss: 0.7199 | Validation Loss: 3.6426\n",
      "Epoch: 93/1000 | Training Loss: 0.7182 | Validation Loss: 3.7081\n",
      "Epoch: 94/1000 | Training Loss: 0.7344 | Validation Loss: 3.6796\n",
      "Epoch: 95/1000 | Training Loss: 0.7224 | Validation Loss: 3.7422\n",
      "Epoch: 96/1000 | Training Loss: 0.7198 | Validation Loss: 3.6824\n",
      "Epoch: 97/1000 | Training Loss: 0.7100 | Validation Loss: 3.6710\n",
      "Epoch: 98/1000 | Training Loss: 0.7100 | Validation Loss: 3.7385\n",
      "Epoch: 99/1000 | Training Loss: 0.7128 | Validation Loss: 3.6248\n",
      "Epoch: 100/1000 | Training Loss: 0.7128 | Validation Loss: 3.7558\n",
      "Epoch: 101/1000 | Training Loss: 0.7146 | Validation Loss: 3.7081\n",
      "Epoch: 102/1000 | Training Loss: 0.7060 | Validation Loss: 3.6941\n",
      "Epoch: 103/1000 | Training Loss: 0.7046 | Validation Loss: 3.7692\n",
      "Epoch: 104/1000 | Training Loss: 0.7244 | Validation Loss: 3.6739\n",
      "Epoch: 105/1000 | Training Loss: 0.7454 | Validation Loss: 3.7774\n",
      "Epoch: 106/1000 | Training Loss: 0.7430 | Validation Loss: 3.7106\n",
      "Epoch: 107/1000 | Training Loss: 0.7279 | Validation Loss: 3.6670\n",
      "Epoch: 108/1000 | Training Loss: 0.7242 | Validation Loss: 3.8171\n",
      "Epoch: 109/1000 | Training Loss: 0.7323 | Validation Loss: 3.6859\n",
      "Epoch: 110/1000 | Training Loss: 0.7387 | Validation Loss: 3.7297\n",
      "Epoch: 111/1000 | Training Loss: 0.7105 | Validation Loss: 3.7517\n",
      "Epoch: 112/1000 | Training Loss: 0.6943 | Validation Loss: 3.6949\n",
      "Epoch: 113/1000 | Training Loss: 0.7093 | Validation Loss: 3.7810\n",
      "Epoch: 114/1000 | Training Loss: 0.7157 | Validation Loss: 3.6969\n",
      "Epoch: 115/1000 | Training Loss: 0.7083 | Validation Loss: 3.7346\n",
      "Epoch: 116/1000 | Training Loss: 0.6881 | Validation Loss: 3.7265\n",
      "Epoch: 117/1000 | Training Loss: 0.6850 | Validation Loss: 3.7095\n",
      "Epoch: 118/1000 | Training Loss: 0.6921 | Validation Loss: 3.7531\n",
      "Epoch: 119/1000 | Training Loss: 0.7007 | Validation Loss: 3.6850\n",
      "Epoch: 120/1000 | Training Loss: 0.7173 | Validation Loss: 3.8196\n",
      "Epoch: 121/1000 | Training Loss: 0.7087 | Validation Loss: 3.7297\n",
      "Epoch: 122/1000 | Training Loss: 0.7046 | Validation Loss: 3.7720\n",
      "Epoch: 123/1000 | Training Loss: 0.7303 | Validation Loss: 3.9258\n",
      "Epoch: 124/1000 | Training Loss: 0.7652 | Validation Loss: 3.7442\n",
      "Epoch: 125/1000 | Training Loss: 0.7709 | Validation Loss: 3.7807\n",
      "Epoch: 126/1000 | Training Loss: 0.7181 | Validation Loss: 3.8634\n",
      "Epoch: 127/1000 | Training Loss: 0.7066 | Validation Loss: 3.7901\n",
      "Epoch: 128/1000 | Training Loss: 0.7505 | Validation Loss: 3.9366\n",
      "Epoch: 129/1000 | Training Loss: 0.7868 | Validation Loss: 3.7759\n",
      "Epoch: 130/1000 | Training Loss: 0.7450 | Validation Loss: 3.7252\n",
      "Epoch: 131/1000 | Training Loss: 0.7658 | Validation Loss: 3.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132/1000 | Training Loss: 0.8048 | Validation Loss: 3.7798\n",
      "Epoch: 133/1000 | Training Loss: 0.7586 | Validation Loss: 3.7599\n",
      "Epoch: 134/1000 | Training Loss: 0.7280 | Validation Loss: 3.9264\n",
      "Epoch: 135/1000 | Training Loss: 0.7762 | Validation Loss: 3.7080\n",
      "Epoch: 136/1000 | Training Loss: 0.7895 | Validation Loss: 3.7455\n",
      "Epoch: 137/1000 | Training Loss: 0.7249 | Validation Loss: 3.8644\n",
      "Epoch: 138/1000 | Training Loss: 0.7518 | Validation Loss: 3.6879\n",
      "Epoch: 139/1000 | Training Loss: 0.7630 | Validation Loss: 3.8144\n",
      "Epoch: 140/1000 | Training Loss: 0.7332 | Validation Loss: 3.8962\n",
      "Epoch: 141/1000 | Training Loss: 0.7297 | Validation Loss: 3.7484\n",
      "Epoch: 142/1000 | Training Loss: 0.7342 | Validation Loss: 3.7506\n",
      "Epoch: 143/1000 | Training Loss: 0.7167 | Validation Loss: 3.8049\n",
      "Epoch: 144/1000 | Training Loss: 0.7171 | Validation Loss: 3.7197\n",
      "Epoch: 145/1000 | Training Loss: 0.7184 | Validation Loss: 3.7819\n",
      "Epoch: 146/1000 | Training Loss: 0.7144 | Validation Loss: 3.8677\n",
      "Epoch: 147/1000 | Training Loss: 0.6964 | Validation Loss: 3.8050\n",
      "Epoch: 148/1000 | Training Loss: 0.7073 | Validation Loss: 3.7587\n",
      "Epoch: 149/1000 | Training Loss: 0.7145 | Validation Loss: 3.7615\n",
      "Epoch: 150/1000 | Training Loss: 0.6985 | Validation Loss: 3.7770\n",
      "Epoch: 151/1000 | Training Loss: 0.7019 | Validation Loss: 3.8352\n",
      "Epoch: 152/1000 | Training Loss: 0.7066 | Validation Loss: 3.8249\n",
      "Epoch: 153/1000 | Training Loss: 0.7012 | Validation Loss: 3.8321\n",
      "Epoch: 154/1000 | Training Loss: 0.7069 | Validation Loss: 3.8260\n",
      "Epoch: 155/1000 | Training Loss: 0.7044 | Validation Loss: 3.7464\n",
      "Epoch: 156/1000 | Training Loss: 0.7100 | Validation Loss: 3.8173\n",
      "Epoch: 157/1000 | Training Loss: 0.7046 | Validation Loss: 3.8015\n",
      "Epoch: 158/1000 | Training Loss: 0.6945 | Validation Loss: 3.7430\n",
      "Epoch: 159/1000 | Training Loss: 0.6955 | Validation Loss: 3.8179\n",
      "Epoch: 160/1000 | Training Loss: 0.6880 | Validation Loss: 3.7721\n",
      "Epoch: 161/1000 | Training Loss: 0.6767 | Validation Loss: 3.7375\n",
      "Epoch: 162/1000 | Training Loss: 0.6840 | Validation Loss: 3.8291\n",
      "Epoch: 163/1000 | Training Loss: 0.6847 | Validation Loss: 3.7464\n",
      "Epoch: 164/1000 | Training Loss: 0.6766 | Validation Loss: 3.7747\n",
      "Epoch: 165/1000 | Training Loss: 0.6732 | Validation Loss: 3.8377\n",
      "Epoch: 166/1000 | Training Loss: 0.6840 | Validation Loss: 3.8334\n",
      "Epoch: 167/1000 | Training Loss: 0.7126 | Validation Loss: 3.8993\n",
      "Epoch: 168/1000 | Training Loss: 0.7447 | Validation Loss: 3.8833\n",
      "Epoch: 169/1000 | Training Loss: 0.7907 | Validation Loss: 3.9064\n",
      "Epoch: 170/1000 | Training Loss: 0.7924 | Validation Loss: 3.8025\n",
      "Epoch: 171/1000 | Training Loss: 0.7186 | Validation Loss: 3.8173\n",
      "Epoch: 172/1000 | Training Loss: 0.6803 | Validation Loss: 3.9655\n",
      "Epoch: 173/1000 | Training Loss: 0.7545 | Validation Loss: 3.8851\n",
      "Epoch: 174/1000 | Training Loss: 0.7905 | Validation Loss: 3.8546\n",
      "Epoch: 175/1000 | Training Loss: 0.7183 | Validation Loss: 3.8370\n",
      "Epoch: 176/1000 | Training Loss: 0.6973 | Validation Loss: 3.8221\n",
      "Epoch: 177/1000 | Training Loss: 0.7223 | Validation Loss: 3.9187\n",
      "Epoch: 178/1000 | Training Loss: 0.7287 | Validation Loss: 3.8521\n",
      "Epoch: 179/1000 | Training Loss: 0.6984 | Validation Loss: 3.7798\n",
      "Epoch: 180/1000 | Training Loss: 0.7030 | Validation Loss: 3.8485\n",
      "Epoch: 181/1000 | Training Loss: 0.7137 | Validation Loss: 3.8144\n",
      "Epoch: 182/1000 | Training Loss: 0.6945 | Validation Loss: 3.7793\n",
      "Epoch: 183/1000 | Training Loss: 0.6864 | Validation Loss: 3.8200\n",
      "Epoch: 184/1000 | Training Loss: 0.6861 | Validation Loss: 3.8195\n",
      "Epoch: 185/1000 | Training Loss: 0.6930 | Validation Loss: 3.8507\n",
      "Epoch: 186/1000 | Training Loss: 0.6946 | Validation Loss: 3.8338\n",
      "Epoch: 187/1000 | Training Loss: 0.6719 | Validation Loss: 3.7988\n",
      "Epoch: 188/1000 | Training Loss: 0.6693 | Validation Loss: 3.8451\n",
      "Epoch: 189/1000 | Training Loss: 0.6926 | Validation Loss: 3.7879\n",
      "Epoch: 190/1000 | Training Loss: 0.6883 | Validation Loss: 3.8385\n",
      "Epoch: 191/1000 | Training Loss: 0.6741 | Validation Loss: 3.8145\n",
      "Epoch: 192/1000 | Training Loss: 0.6671 | Validation Loss: 3.8481\n",
      "Epoch: 193/1000 | Training Loss: 0.6697 | Validation Loss: 3.8682\n",
      "Epoch: 194/1000 | Training Loss: 0.6859 | Validation Loss: 3.8218\n",
      "Epoch: 195/1000 | Training Loss: 0.6962 | Validation Loss: 3.9001\n",
      "Epoch: 196/1000 | Training Loss: 0.7081 | Validation Loss: 3.8730\n",
      "Epoch: 197/1000 | Training Loss: 0.7062 | Validation Loss: 3.8444\n",
      "Epoch: 198/1000 | Training Loss: 0.7144 | Validation Loss: 3.9778\n",
      "Epoch: 199/1000 | Training Loss: 0.7016 | Validation Loss: 3.8139\n",
      "Epoch: 200/1000 | Training Loss: 0.6755 | Validation Loss: 3.8230\n",
      "Epoch: 201/1000 | Training Loss: 0.6600 | Validation Loss: 3.9385\n",
      "Epoch: 202/1000 | Training Loss: 0.6842 | Validation Loss: 3.7950\n",
      "Epoch: 203/1000 | Training Loss: 0.7060 | Validation Loss: 3.9350\n",
      "Epoch: 204/1000 | Training Loss: 0.7093 | Validation Loss: 3.9516\n",
      "Epoch: 205/1000 | Training Loss: 0.7084 | Validation Loss: 3.8827\n",
      "Epoch: 206/1000 | Training Loss: 0.7084 | Validation Loss: 3.9564\n",
      "Epoch: 207/1000 | Training Loss: 0.7106 | Validation Loss: 3.8745\n",
      "Epoch: 208/1000 | Training Loss: 0.6816 | Validation Loss: 3.8235\n",
      "Epoch: 209/1000 | Training Loss: 0.6696 | Validation Loss: 3.9117\n",
      "Epoch: 210/1000 | Training Loss: 0.6802 | Validation Loss: 3.8780\n",
      "Epoch: 211/1000 | Training Loss: 0.6987 | Validation Loss: 3.9200\n",
      "Epoch: 212/1000 | Training Loss: 0.6970 | Validation Loss: 3.9033\n",
      "Epoch: 213/1000 | Training Loss: 0.6792 | Validation Loss: 3.8504\n",
      "Epoch: 214/1000 | Training Loss: 0.6728 | Validation Loss: 3.9079\n",
      "Epoch: 215/1000 | Training Loss: 0.6737 | Validation Loss: 3.8769\n",
      "Epoch: 216/1000 | Training Loss: 0.6622 | Validation Loss: 3.9118\n",
      "Epoch: 217/1000 | Training Loss: 0.6647 | Validation Loss: 3.9285\n",
      "Epoch: 218/1000 | Training Loss: 0.6969 | Validation Loss: 3.8702\n",
      "Epoch: 219/1000 | Training Loss: 0.7205 | Validation Loss: 3.9625\n",
      "Epoch: 220/1000 | Training Loss: 0.6972 | Validation Loss: 3.9151\n",
      "Epoch: 221/1000 | Training Loss: 0.6710 | Validation Loss: 3.9000\n",
      "Epoch: 222/1000 | Training Loss: 0.6657 | Validation Loss: 3.9292\n",
      "Epoch: 223/1000 | Training Loss: 0.6703 | Validation Loss: 3.8586\n",
      "Epoch: 224/1000 | Training Loss: 0.6922 | Validation Loss: 3.9786\n",
      "Epoch: 225/1000 | Training Loss: 0.7037 | Validation Loss: 3.9553\n",
      "Epoch: 226/1000 | Training Loss: 0.7059 | Validation Loss: 3.8954\n",
      "Epoch: 227/1000 | Training Loss: 0.6924 | Validation Loss: 3.9478\n",
      "Epoch: 228/1000 | Training Loss: 0.6816 | Validation Loss: 3.8828\n",
      "Epoch: 229/1000 | Training Loss: 0.6552 | Validation Loss: 3.9370\n",
      "Epoch: 230/1000 | Training Loss: 0.6608 | Validation Loss: 3.9784\n",
      "Epoch: 231/1000 | Training Loss: 0.6761 | Validation Loss: 3.8440\n",
      "Epoch: 232/1000 | Training Loss: 0.6658 | Validation Loss: 3.9374\n",
      "Epoch: 233/1000 | Training Loss: 0.6543 | Validation Loss: 3.9749\n",
      "Epoch: 234/1000 | Training Loss: 0.6526 | Validation Loss: 3.9215\n",
      "Epoch: 235/1000 | Training Loss: 0.6577 | Validation Loss: 4.0078\n",
      "Epoch: 236/1000 | Training Loss: 0.6703 | Validation Loss: 3.9091\n",
      "Epoch: 237/1000 | Training Loss: 0.6784 | Validation Loss: 3.9027\n",
      "Epoch: 238/1000 | Training Loss: 0.6908 | Validation Loss: 4.0334\n",
      "Epoch: 239/1000 | Training Loss: 0.6987 | Validation Loss: 3.9171\n",
      "Epoch: 240/1000 | Training Loss: 0.7057 | Validation Loss: 3.9964\n",
      "Epoch: 241/1000 | Training Loss: 0.6871 | Validation Loss: 3.9783\n",
      "Epoch: 242/1000 | Training Loss: 0.6648 | Validation Loss: 3.9044\n",
      "Epoch: 243/1000 | Training Loss: 0.6489 | Validation Loss: 3.9498\n",
      "Epoch: 244/1000 | Training Loss: 0.6690 | Validation Loss: 3.9801\n",
      "Epoch: 245/1000 | Training Loss: 0.6849 | Validation Loss: 3.9744\n",
      "Epoch: 246/1000 | Training Loss: 0.6682 | Validation Loss: 3.9313\n",
      "Epoch: 247/1000 | Training Loss: 0.6692 | Validation Loss: 3.9916\n",
      "Epoch: 248/1000 | Training Loss: 0.6789 | Validation Loss: 3.9955\n",
      "Epoch: 249/1000 | Training Loss: 0.6646 | Validation Loss: 3.9126\n",
      "Epoch: 250/1000 | Training Loss: 0.6667 | Validation Loss: 4.0605\n",
      "Epoch: 251/1000 | Training Loss: 0.6636 | Validation Loss: 3.9454\n",
      "Epoch: 252/1000 | Training Loss: 0.6468 | Validation Loss: 3.9641\n",
      "Epoch: 253/1000 | Training Loss: 0.6668 | Validation Loss: 4.1231\n",
      "Epoch: 254/1000 | Training Loss: 0.6985 | Validation Loss: 3.9716\n",
      "Epoch: 255/1000 | Training Loss: 0.6983 | Validation Loss: 3.9542\n",
      "Epoch: 256/1000 | Training Loss: 0.7003 | Validation Loss: 4.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 257/1000 | Training Loss: 0.7037 | Validation Loss: 3.9390\n",
      "Epoch: 258/1000 | Training Loss: 0.6972 | Validation Loss: 4.0369\n",
      "Epoch: 259/1000 | Training Loss: 0.6725 | Validation Loss: 4.0200\n",
      "Epoch: 260/1000 | Training Loss: 0.6581 | Validation Loss: 3.9786\n",
      "Epoch: 261/1000 | Training Loss: 0.6681 | Validation Loss: 4.1065\n",
      "Epoch: 262/1000 | Training Loss: 0.7012 | Validation Loss: 3.9978\n",
      "Epoch: 263/1000 | Training Loss: 0.6831 | Validation Loss: 3.9963\n",
      "Epoch: 264/1000 | Training Loss: 0.6847 | Validation Loss: 4.0898\n",
      "Epoch: 265/1000 | Training Loss: 0.6767 | Validation Loss: 4.0013\n",
      "Epoch: 266/1000 | Training Loss: 0.6708 | Validation Loss: 4.0239\n",
      "Epoch: 267/1000 | Training Loss: 0.6718 | Validation Loss: 3.9939\n",
      "Epoch: 268/1000 | Training Loss: 0.6601 | Validation Loss: 4.0131\n",
      "Epoch: 269/1000 | Training Loss: 0.6558 | Validation Loss: 4.1006\n",
      "Epoch: 270/1000 | Training Loss: 0.6831 | Validation Loss: 4.0379\n",
      "Epoch: 271/1000 | Training Loss: 0.6590 | Validation Loss: 4.0108\n",
      "Epoch: 272/1000 | Training Loss: 0.6416 | Validation Loss: 4.0230\n",
      "Epoch: 273/1000 | Training Loss: 0.6637 | Validation Loss: 4.0787\n",
      "Epoch: 274/1000 | Training Loss: 0.6656 | Validation Loss: 4.0562\n",
      "Epoch: 275/1000 | Training Loss: 0.6778 | Validation Loss: 4.0301\n",
      "Epoch: 276/1000 | Training Loss: 0.6771 | Validation Loss: 4.0407\n",
      "Epoch: 277/1000 | Training Loss: 0.6684 | Validation Loss: 4.0089\n",
      "Epoch: 278/1000 | Training Loss: 0.6526 | Validation Loss: 4.0675\n",
      "Epoch: 279/1000 | Training Loss: 0.6506 | Validation Loss: 4.1043\n",
      "Epoch: 280/1000 | Training Loss: 0.6537 | Validation Loss: 4.0679\n",
      "Epoch: 281/1000 | Training Loss: 0.6571 | Validation Loss: 4.0599\n",
      "Epoch: 282/1000 | Training Loss: 0.6548 | Validation Loss: 4.0972\n",
      "Epoch: 283/1000 | Training Loss: 0.6433 | Validation Loss: 4.0577\n",
      "Epoch: 284/1000 | Training Loss: 0.6540 | Validation Loss: 4.1145\n",
      "Epoch: 285/1000 | Training Loss: 0.6640 | Validation Loss: 4.1008\n",
      "Epoch: 286/1000 | Training Loss: 0.7072 | Validation Loss: 4.1281\n",
      "Epoch: 287/1000 | Training Loss: 0.7316 | Validation Loss: 4.1396\n",
      "Epoch: 288/1000 | Training Loss: 0.7002 | Validation Loss: 4.0818\n",
      "Epoch: 289/1000 | Training Loss: 0.6456 | Validation Loss: 4.0798\n",
      "Epoch: 290/1000 | Training Loss: 0.6617 | Validation Loss: 4.1367\n",
      "Epoch: 291/1000 | Training Loss: 0.6985 | Validation Loss: 4.1135\n",
      "Epoch: 292/1000 | Training Loss: 0.6729 | Validation Loss: 4.0155\n",
      "Epoch: 293/1000 | Training Loss: 0.6390 | Validation Loss: 4.0556\n",
      "Epoch: 294/1000 | Training Loss: 0.6321 | Validation Loss: 4.0710\n",
      "Epoch: 295/1000 | Training Loss: 0.6546 | Validation Loss: 4.0611\n",
      "Epoch: 296/1000 | Training Loss: 0.6753 | Validation Loss: 4.1055\n",
      "Epoch: 297/1000 | Training Loss: 0.6698 | Validation Loss: 4.0856\n",
      "Epoch: 298/1000 | Training Loss: 0.6535 | Validation Loss: 4.1144\n",
      "Epoch: 299/1000 | Training Loss: 0.6640 | Validation Loss: 4.1316\n",
      "Epoch: 300/1000 | Training Loss: 0.6960 | Validation Loss: 4.1222\n",
      "Epoch: 301/1000 | Training Loss: 0.6894 | Validation Loss: 4.0930\n",
      "Epoch: 302/1000 | Training Loss: 0.6554 | Validation Loss: 4.1134\n",
      "Epoch: 303/1000 | Training Loss: 0.6328 | Validation Loss: 4.1598\n",
      "Epoch: 304/1000 | Training Loss: 0.6648 | Validation Loss: 4.1526\n",
      "Epoch: 305/1000 | Training Loss: 0.7056 | Validation Loss: 4.0812\n",
      "Epoch: 306/1000 | Training Loss: 0.6730 | Validation Loss: 4.0407\n",
      "Epoch: 307/1000 | Training Loss: 0.6391 | Validation Loss: 4.1067\n",
      "Epoch: 308/1000 | Training Loss: 0.6437 | Validation Loss: 4.1180\n",
      "Epoch: 309/1000 | Training Loss: 0.6624 | Validation Loss: 4.1584\n",
      "Epoch: 310/1000 | Training Loss: 0.6681 | Validation Loss: 4.0689\n",
      "Epoch: 311/1000 | Training Loss: 0.6604 | Validation Loss: 4.0973\n",
      "Epoch: 312/1000 | Training Loss: 0.6430 | Validation Loss: 4.1596\n",
      "Epoch: 313/1000 | Training Loss: 0.6670 | Validation Loss: 4.1143\n",
      "Epoch: 314/1000 | Training Loss: 0.6649 | Validation Loss: 4.1121\n",
      "Epoch: 315/1000 | Training Loss: 0.6519 | Validation Loss: 4.1422\n",
      "Epoch: 316/1000 | Training Loss: 0.6473 | Validation Loss: 4.0801\n",
      "Epoch: 317/1000 | Training Loss: 0.6489 | Validation Loss: 4.1042\n",
      "Epoch: 318/1000 | Training Loss: 0.6476 | Validation Loss: 4.1660\n",
      "Epoch: 319/1000 | Training Loss: 0.6510 | Validation Loss: 4.0727\n",
      "Epoch: 320/1000 | Training Loss: 0.6372 | Validation Loss: 4.0983\n",
      "Epoch: 321/1000 | Training Loss: 0.6293 | Validation Loss: 4.1889\n",
      "Epoch: 322/1000 | Training Loss: 0.6441 | Validation Loss: 4.1212\n",
      "Epoch: 323/1000 | Training Loss: 0.6297 | Validation Loss: 4.1142\n",
      "Epoch: 324/1000 | Training Loss: 0.6485 | Validation Loss: 4.2090\n",
      "Epoch: 325/1000 | Training Loss: 0.6797 | Validation Loss: 4.1238\n",
      "Epoch: 326/1000 | Training Loss: 0.6905 | Validation Loss: 4.1834\n",
      "Epoch: 327/1000 | Training Loss: 0.6879 | Validation Loss: 4.3313\n",
      "Epoch: 328/1000 | Training Loss: 0.7054 | Validation Loss: 4.1260\n",
      "Epoch: 329/1000 | Training Loss: 0.6648 | Validation Loss: 4.0728\n",
      "Epoch: 330/1000 | Training Loss: 0.6522 | Validation Loss: 4.2685\n",
      "Epoch: 331/1000 | Training Loss: 0.6562 | Validation Loss: 4.1685\n",
      "Epoch: 332/1000 | Training Loss: 0.6596 | Validation Loss: 4.1883\n",
      "Epoch: 333/1000 | Training Loss: 0.6722 | Validation Loss: 4.2013\n",
      "Epoch: 334/1000 | Training Loss: 0.6890 | Validation Loss: 4.1978\n",
      "Epoch: 335/1000 | Training Loss: 0.6947 | Validation Loss: 4.2008\n",
      "Epoch: 336/1000 | Training Loss: 0.6680 | Validation Loss: 4.1643\n",
      "Epoch: 337/1000 | Training Loss: 0.6526 | Validation Loss: 4.2392\n",
      "Epoch: 338/1000 | Training Loss: 0.6700 | Validation Loss: 4.1547\n",
      "Epoch: 339/1000 | Training Loss: 0.6929 | Validation Loss: 4.2428\n",
      "Epoch: 340/1000 | Training Loss: 0.7127 | Validation Loss: 4.3158\n",
      "Epoch: 341/1000 | Training Loss: 0.7122 | Validation Loss: 4.0916\n",
      "Epoch: 342/1000 | Training Loss: 0.6818 | Validation Loss: 4.2816\n",
      "Epoch: 343/1000 | Training Loss: 0.6836 | Validation Loss: 4.2233\n",
      "Epoch: 344/1000 | Training Loss: 0.6621 | Validation Loss: 4.2116\n",
      "Epoch: 345/1000 | Training Loss: 0.7078 | Validation Loss: 4.2943\n",
      "Epoch: 346/1000 | Training Loss: 0.7165 | Validation Loss: 4.0730\n",
      "Epoch: 347/1000 | Training Loss: 0.7014 | Validation Loss: 4.1271\n",
      "Epoch: 348/1000 | Training Loss: 0.6440 | Validation Loss: 4.2562\n",
      "Epoch: 349/1000 | Training Loss: 0.6866 | Validation Loss: 4.2058\n",
      "Epoch: 350/1000 | Training Loss: 0.6807 | Validation Loss: 4.2886\n",
      "Epoch: 351/1000 | Training Loss: 0.6835 | Validation Loss: 4.1623\n",
      "Epoch: 352/1000 | Training Loss: 0.6445 | Validation Loss: 4.0640\n",
      "Epoch: 353/1000 | Training Loss: 0.6747 | Validation Loss: 4.3138\n",
      "Epoch: 354/1000 | Training Loss: 0.6813 | Validation Loss: 4.1910\n",
      "Epoch: 355/1000 | Training Loss: 0.6728 | Validation Loss: 4.1552\n",
      "Epoch: 356/1000 | Training Loss: 0.6710 | Validation Loss: 4.3996\n",
      "Epoch: 357/1000 | Training Loss: 0.7115 | Validation Loss: 4.1192\n",
      "Epoch: 358/1000 | Training Loss: 0.6739 | Validation Loss: 4.1408\n",
      "Epoch: 359/1000 | Training Loss: 0.6669 | Validation Loss: 4.3197\n",
      "Epoch: 360/1000 | Training Loss: 0.6662 | Validation Loss: 4.2558\n",
      "Epoch: 361/1000 | Training Loss: 0.6669 | Validation Loss: 4.2413\n",
      "Epoch: 362/1000 | Training Loss: 0.6580 | Validation Loss: 4.1873\n",
      "Epoch: 363/1000 | Training Loss: 0.6379 | Validation Loss: 4.1129\n",
      "Epoch: 364/1000 | Training Loss: 0.6485 | Validation Loss: 4.2578\n",
      "Epoch: 365/1000 | Training Loss: 0.6498 | Validation Loss: 4.1870\n",
      "Epoch: 366/1000 | Training Loss: 0.6570 | Validation Loss: 4.2233\n",
      "Epoch: 367/1000 | Training Loss: 0.6608 | Validation Loss: 4.2588\n",
      "Epoch: 368/1000 | Training Loss: 0.6553 | Validation Loss: 4.2812\n",
      "Epoch: 369/1000 | Training Loss: 0.6552 | Validation Loss: 4.2424\n",
      "Epoch: 370/1000 | Training Loss: 0.6572 | Validation Loss: 4.1533\n",
      "Epoch: 371/1000 | Training Loss: 0.6391 | Validation Loss: 4.1909\n",
      "Epoch: 372/1000 | Training Loss: 0.6368 | Validation Loss: 4.2519\n",
      "Epoch: 373/1000 | Training Loss: 0.6304 | Validation Loss: 4.2710\n",
      "Epoch: 374/1000 | Training Loss: 0.6231 | Validation Loss: 4.2731\n",
      "Epoch: 375/1000 | Training Loss: 0.6254 | Validation Loss: 4.2161\n",
      "Epoch: 376/1000 | Training Loss: 0.6411 | Validation Loss: 4.2283\n",
      "Epoch: 377/1000 | Training Loss: 0.6491 | Validation Loss: 4.1980\n",
      "Epoch: 378/1000 | Training Loss: 0.6260 | Validation Loss: 4.2509\n",
      "Epoch: 379/1000 | Training Loss: 0.6293 | Validation Loss: 4.3191\n",
      "Epoch: 380/1000 | Training Loss: 0.6275 | Validation Loss: 4.2521\n",
      "Epoch: 381/1000 | Training Loss: 0.6225 | Validation Loss: 4.2361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 382/1000 | Training Loss: 0.6206 | Validation Loss: 4.2740\n",
      "Epoch: 383/1000 | Training Loss: 0.6207 | Validation Loss: 4.2245\n",
      "Epoch: 384/1000 | Training Loss: 0.6055 | Validation Loss: 4.2410\n",
      "Epoch: 385/1000 | Training Loss: 0.6031 | Validation Loss: 4.3043\n",
      "Epoch: 386/1000 | Training Loss: 0.6101 | Validation Loss: 4.2336\n",
      "Epoch: 387/1000 | Training Loss: 0.6172 | Validation Loss: 4.2660\n",
      "Epoch: 388/1000 | Training Loss: 0.6269 | Validation Loss: 4.3107\n",
      "Epoch: 389/1000 | Training Loss: 0.6601 | Validation Loss: 4.2583\n",
      "Epoch: 390/1000 | Training Loss: 0.6840 | Validation Loss: 4.3210\n",
      "Epoch: 391/1000 | Training Loss: 0.6715 | Validation Loss: 4.2586\n",
      "Epoch: 392/1000 | Training Loss: 0.6230 | Validation Loss: 4.2448\n",
      "Epoch: 393/1000 | Training Loss: 0.6155 | Validation Loss: 4.3678\n",
      "Epoch: 394/1000 | Training Loss: 0.6346 | Validation Loss: 4.2790\n",
      "Epoch: 395/1000 | Training Loss: 0.6550 | Validation Loss: 4.2745\n",
      "Epoch: 396/1000 | Training Loss: 0.6553 | Validation Loss: 4.2720\n",
      "Epoch: 397/1000 | Training Loss: 0.6277 | Validation Loss: 4.2202\n",
      "Epoch: 398/1000 | Training Loss: 0.6068 | Validation Loss: 4.2819\n",
      "Epoch: 399/1000 | Training Loss: 0.6069 | Validation Loss: 4.2996\n",
      "Epoch: 400/1000 | Training Loss: 0.6235 | Validation Loss: 4.2802\n",
      "Epoch: 401/1000 | Training Loss: 0.6405 | Validation Loss: 4.2824\n",
      "Epoch: 402/1000 | Training Loss: 0.6326 | Validation Loss: 4.2814\n",
      "Epoch: 403/1000 | Training Loss: 0.6188 | Validation Loss: 4.3022\n",
      "Epoch: 404/1000 | Training Loss: 0.6076 | Validation Loss: 4.3235\n",
      "Epoch: 405/1000 | Training Loss: 0.6065 | Validation Loss: 4.2829\n",
      "Epoch: 406/1000 | Training Loss: 0.6134 | Validation Loss: 4.3297\n",
      "Epoch: 407/1000 | Training Loss: 0.6325 | Validation Loss: 4.3419\n",
      "Epoch: 408/1000 | Training Loss: 0.6419 | Validation Loss: 4.3155\n",
      "Epoch: 409/1000 | Training Loss: 0.6318 | Validation Loss: 4.3228\n",
      "Epoch: 410/1000 | Training Loss: 0.6154 | Validation Loss: 4.2648\n",
      "Epoch: 411/1000 | Training Loss: 0.6154 | Validation Loss: 4.3173\n",
      "Epoch: 412/1000 | Training Loss: 0.6049 | Validation Loss: 4.3237\n",
      "Epoch: 413/1000 | Training Loss: 0.5998 | Validation Loss: 4.3156\n",
      "Epoch: 414/1000 | Training Loss: 0.5976 | Validation Loss: 4.3138\n",
      "Epoch: 415/1000 | Training Loss: 0.6154 | Validation Loss: 4.3415\n",
      "Epoch: 416/1000 | Training Loss: 0.6337 | Validation Loss: 4.3852\n",
      "Epoch: 417/1000 | Training Loss: 0.6565 | Validation Loss: 4.3480\n",
      "Epoch: 418/1000 | Training Loss: 0.6524 | Validation Loss: 4.3536\n",
      "Epoch: 419/1000 | Training Loss: 0.6300 | Validation Loss: 4.3837\n",
      "Epoch: 420/1000 | Training Loss: 0.6180 | Validation Loss: 4.3209\n",
      "Epoch: 421/1000 | Training Loss: 0.6265 | Validation Loss: 4.4103\n",
      "Epoch: 422/1000 | Training Loss: 0.6335 | Validation Loss: 4.3829\n",
      "Epoch: 423/1000 | Training Loss: 0.6354 | Validation Loss: 4.2598\n",
      "Epoch: 424/1000 | Training Loss: 0.6418 | Validation Loss: 4.4905\n",
      "Epoch: 425/1000 | Training Loss: 0.6446 | Validation Loss: 4.3416\n",
      "Epoch: 426/1000 | Training Loss: 0.6192 | Validation Loss: 4.3071\n",
      "Epoch: 427/1000 | Training Loss: 0.6315 | Validation Loss: 4.4324\n",
      "Epoch: 428/1000 | Training Loss: 0.6469 | Validation Loss: 4.2852\n",
      "Epoch: 429/1000 | Training Loss: 0.6489 | Validation Loss: 4.3882\n",
      "Epoch: 430/1000 | Training Loss: 0.6172 | Validation Loss: 4.4150\n",
      "Epoch: 431/1000 | Training Loss: 0.6105 | Validation Loss: 4.3185\n",
      "Epoch: 432/1000 | Training Loss: 0.6437 | Validation Loss: 4.4035\n",
      "Epoch: 433/1000 | Training Loss: 0.6436 | Validation Loss: 4.3309\n",
      "Epoch: 434/1000 | Training Loss: 0.6042 | Validation Loss: 4.3266\n",
      "Epoch: 435/1000 | Training Loss: 0.6150 | Validation Loss: 4.4806\n",
      "Epoch: 436/1000 | Training Loss: 0.6402 | Validation Loss: 4.3168\n",
      "Epoch: 437/1000 | Training Loss: 0.6517 | Validation Loss: 4.3595\n",
      "Epoch: 438/1000 | Training Loss: 0.6358 | Validation Loss: 4.5227\n",
      "Epoch: 439/1000 | Training Loss: 0.6404 | Validation Loss: 4.3307\n",
      "Epoch: 440/1000 | Training Loss: 0.6466 | Validation Loss: 4.4270\n",
      "Epoch: 441/1000 | Training Loss: 0.6472 | Validation Loss: 4.4229\n",
      "Epoch: 442/1000 | Training Loss: 0.6419 | Validation Loss: 4.3400\n",
      "Epoch: 443/1000 | Training Loss: 0.6372 | Validation Loss: 4.4841\n",
      "Epoch: 444/1000 | Training Loss: 0.6397 | Validation Loss: 4.4101\n",
      "Epoch: 445/1000 | Training Loss: 0.6585 | Validation Loss: 4.3632\n",
      "Epoch: 446/1000 | Training Loss: 0.6182 | Validation Loss: 4.4717\n",
      "Epoch: 447/1000 | Training Loss: 0.6164 | Validation Loss: 4.4016\n",
      "Epoch: 448/1000 | Training Loss: 0.6573 | Validation Loss: 4.4251\n",
      "Epoch: 449/1000 | Training Loss: 0.6266 | Validation Loss: 4.3937\n",
      "Epoch: 450/1000 | Training Loss: 0.6094 | Validation Loss: 4.4130\n",
      "Epoch: 451/1000 | Training Loss: 0.6744 | Validation Loss: 4.4893\n",
      "Epoch: 452/1000 | Training Loss: 0.6756 | Validation Loss: 4.4025\n",
      "Epoch: 453/1000 | Training Loss: 0.6530 | Validation Loss: 4.3763\n",
      "Epoch: 454/1000 | Training Loss: 0.6414 | Validation Loss: 4.4975\n",
      "Epoch: 455/1000 | Training Loss: 0.6512 | Validation Loss: 4.3841\n",
      "Epoch: 456/1000 | Training Loss: 0.6287 | Validation Loss: 4.4078\n",
      "Epoch: 457/1000 | Training Loss: 0.6284 | Validation Loss: 4.4235\n",
      "Epoch: 458/1000 | Training Loss: 0.6298 | Validation Loss: 4.4230\n",
      "Epoch: 459/1000 | Training Loss: 0.6397 | Validation Loss: 4.4660\n",
      "Epoch: 460/1000 | Training Loss: 0.6385 | Validation Loss: 4.3689\n",
      "Epoch: 461/1000 | Training Loss: 0.6392 | Validation Loss: 4.4904\n",
      "Epoch: 462/1000 | Training Loss: 0.6461 | Validation Loss: 4.5969\n",
      "Epoch: 463/1000 | Training Loss: 0.6533 | Validation Loss: 4.4891\n",
      "Epoch: 464/1000 | Training Loss: 0.6392 | Validation Loss: 4.4582\n",
      "Epoch: 465/1000 | Training Loss: 0.6299 | Validation Loss: 4.4618\n",
      "Epoch: 466/1000 | Training Loss: 0.6350 | Validation Loss: 4.3754\n",
      "Epoch: 467/1000 | Training Loss: 0.6597 | Validation Loss: 4.4708\n",
      "Epoch: 468/1000 | Training Loss: 0.6479 | Validation Loss: 4.5469\n",
      "Epoch: 469/1000 | Training Loss: 0.6454 | Validation Loss: 4.3277\n",
      "Epoch: 470/1000 | Training Loss: 0.6301 | Validation Loss: 4.3819\n",
      "Epoch: 471/1000 | Training Loss: 0.6088 | Validation Loss: 4.5081\n",
      "Epoch: 472/1000 | Training Loss: 0.6158 | Validation Loss: 4.3961\n",
      "Epoch: 473/1000 | Training Loss: 0.6259 | Validation Loss: 4.4295\n",
      "Epoch: 474/1000 | Training Loss: 0.6278 | Validation Loss: 4.4867\n",
      "Epoch: 475/1000 | Training Loss: 0.6370 | Validation Loss: 4.3981\n",
      "Epoch: 476/1000 | Training Loss: 0.6303 | Validation Loss: 4.4827\n",
      "Epoch: 477/1000 | Training Loss: 0.6030 | Validation Loss: 4.4729\n",
      "Epoch: 478/1000 | Training Loss: 0.6015 | Validation Loss: 4.3750\n",
      "Epoch: 479/1000 | Training Loss: 0.6210 | Validation Loss: 4.4770\n",
      "Epoch: 480/1000 | Training Loss: 0.6445 | Validation Loss: 4.4899\n",
      "Epoch: 481/1000 | Training Loss: 0.6494 | Validation Loss: 4.3654\n",
      "Epoch: 482/1000 | Training Loss: 0.6271 | Validation Loss: 4.4901\n",
      "Epoch: 483/1000 | Training Loss: 0.6128 | Validation Loss: 4.4719\n",
      "Epoch: 484/1000 | Training Loss: 0.6116 | Validation Loss: 4.4349\n",
      "Epoch: 485/1000 | Training Loss: 0.6066 | Validation Loss: 4.5027\n",
      "Epoch: 486/1000 | Training Loss: 0.6331 | Validation Loss: 4.4432\n",
      "Epoch: 487/1000 | Training Loss: 0.6583 | Validation Loss: 4.4711\n",
      "Epoch: 488/1000 | Training Loss: 0.6081 | Validation Loss: 4.4523\n",
      "Epoch: 489/1000 | Training Loss: 0.6144 | Validation Loss: 4.4365\n",
      "Epoch: 490/1000 | Training Loss: 0.6796 | Validation Loss: 4.5872\n",
      "Epoch: 491/1000 | Training Loss: 0.6688 | Validation Loss: 4.4719\n",
      "Epoch: 492/1000 | Training Loss: 0.6392 | Validation Loss: 4.4436\n",
      "Epoch: 493/1000 | Training Loss: 0.6449 | Validation Loss: 4.5413\n",
      "Epoch: 494/1000 | Training Loss: 0.6127 | Validation Loss: 4.4824\n",
      "Epoch: 495/1000 | Training Loss: 0.6433 | Validation Loss: 4.4764\n",
      "Epoch: 496/1000 | Training Loss: 0.6733 | Validation Loss: 4.7024\n",
      "Epoch: 497/1000 | Training Loss: 0.6810 | Validation Loss: 4.4116\n",
      "Epoch: 498/1000 | Training Loss: 0.6443 | Validation Loss: 4.4666\n",
      "Epoch: 499/1000 | Training Loss: 0.7108 | Validation Loss: 4.7416\n",
      "Epoch: 500/1000 | Training Loss: 0.7077 | Validation Loss: 4.5021\n",
      "Epoch: 501/1000 | Training Loss: 0.6315 | Validation Loss: 4.4438\n",
      "Epoch: 502/1000 | Training Loss: 0.6737 | Validation Loss: 4.6251\n",
      "Epoch: 503/1000 | Training Loss: 0.6741 | Validation Loss: 4.5106\n",
      "Epoch: 504/1000 | Training Loss: 0.6450 | Validation Loss: 4.3972\n",
      "Epoch: 505/1000 | Training Loss: 0.6657 | Validation Loss: 4.6294\n",
      "Epoch: 506/1000 | Training Loss: 0.6492 | Validation Loss: 4.5687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 507/1000 | Training Loss: 0.6401 | Validation Loss: 4.4500\n",
      "Epoch: 508/1000 | Training Loss: 0.6596 | Validation Loss: 4.5919\n",
      "Epoch: 509/1000 | Training Loss: 0.6836 | Validation Loss: 4.6079\n",
      "Epoch: 510/1000 | Training Loss: 0.6466 | Validation Loss: 4.4745\n",
      "Epoch: 511/1000 | Training Loss: 0.6427 | Validation Loss: 4.5139\n",
      "Epoch: 512/1000 | Training Loss: 0.6397 | Validation Loss: 4.5011\n",
      "Epoch: 513/1000 | Training Loss: 0.6161 | Validation Loss: 4.4907\n",
      "Epoch: 514/1000 | Training Loss: 0.6397 | Validation Loss: 4.5498\n",
      "Epoch: 515/1000 | Training Loss: 0.6440 | Validation Loss: 4.5005\n",
      "Epoch: 516/1000 | Training Loss: 0.6217 | Validation Loss: 4.4926\n",
      "Epoch: 517/1000 | Training Loss: 0.6261 | Validation Loss: 4.4712\n",
      "Epoch: 518/1000 | Training Loss: 0.6151 | Validation Loss: 4.4526\n",
      "Epoch: 519/1000 | Training Loss: 0.6093 | Validation Loss: 4.4691\n",
      "Epoch: 520/1000 | Training Loss: 0.6158 | Validation Loss: 4.5600\n",
      "Epoch: 521/1000 | Training Loss: 0.6182 | Validation Loss: 4.5075\n",
      "Epoch: 522/1000 | Training Loss: 0.6122 | Validation Loss: 4.4623\n",
      "Epoch: 523/1000 | Training Loss: 0.5915 | Validation Loss: 4.5390\n",
      "Epoch: 524/1000 | Training Loss: 0.5978 | Validation Loss: 4.4527\n",
      "Epoch: 525/1000 | Training Loss: 0.5808 | Validation Loss: 4.4495\n",
      "Epoch: 526/1000 | Training Loss: 0.5873 | Validation Loss: 4.5648\n",
      "Epoch: 527/1000 | Training Loss: 0.5918 | Validation Loss: 4.5395\n",
      "Epoch: 528/1000 | Training Loss: 0.5881 | Validation Loss: 4.5062\n",
      "Epoch: 529/1000 | Training Loss: 0.6053 | Validation Loss: 4.5529\n",
      "Epoch: 530/1000 | Training Loss: 0.6098 | Validation Loss: 4.4885\n",
      "Epoch: 531/1000 | Training Loss: 0.6112 | Validation Loss: 4.4894\n",
      "Epoch: 532/1000 | Training Loss: 0.5896 | Validation Loss: 4.5603\n",
      "Epoch: 533/1000 | Training Loss: 0.5764 | Validation Loss: 4.5593\n",
      "Epoch: 534/1000 | Training Loss: 0.5748 | Validation Loss: 4.5524\n",
      "Epoch: 535/1000 | Training Loss: 0.5781 | Validation Loss: 4.5456\n",
      "Epoch: 536/1000 | Training Loss: 0.5935 | Validation Loss: 4.5360\n",
      "Epoch: 537/1000 | Training Loss: 0.6163 | Validation Loss: 4.5452\n",
      "Epoch: 538/1000 | Training Loss: 0.6122 | Validation Loss: 4.5694\n",
      "Epoch: 539/1000 | Training Loss: 0.6085 | Validation Loss: 4.5361\n",
      "Epoch: 540/1000 | Training Loss: 0.5942 | Validation Loss: 4.5814\n",
      "Epoch: 541/1000 | Training Loss: 0.5896 | Validation Loss: 4.4860\n",
      "Epoch: 542/1000 | Training Loss: 0.5781 | Validation Loss: 4.5008\n",
      "Epoch: 543/1000 | Training Loss: 0.5884 | Validation Loss: 4.5671\n",
      "Epoch: 544/1000 | Training Loss: 0.5861 | Validation Loss: 4.5293\n",
      "Epoch: 545/1000 | Training Loss: 0.5841 | Validation Loss: 4.5327\n",
      "Epoch: 546/1000 | Training Loss: 0.5701 | Validation Loss: 4.6151\n",
      "Epoch: 547/1000 | Training Loss: 0.5705 | Validation Loss: 4.5490\n",
      "Epoch: 548/1000 | Training Loss: 0.5653 | Validation Loss: 4.5096\n",
      "Epoch: 549/1000 | Training Loss: 0.5811 | Validation Loss: 4.6057\n",
      "Epoch: 550/1000 | Training Loss: 0.5883 | Validation Loss: 4.6098\n",
      "Epoch: 551/1000 | Training Loss: 0.6035 | Validation Loss: 4.6044\n",
      "Epoch: 552/1000 | Training Loss: 0.6099 | Validation Loss: 4.6172\n",
      "Epoch: 553/1000 | Training Loss: 0.6067 | Validation Loss: 4.5835\n",
      "Epoch: 554/1000 | Training Loss: 0.5961 | Validation Loss: 4.5803\n",
      "Epoch: 555/1000 | Training Loss: 0.5841 | Validation Loss: 4.5810\n",
      "Epoch: 556/1000 | Training Loss: 0.6051 | Validation Loss: 4.6675\n",
      "Epoch: 557/1000 | Training Loss: 0.6231 | Validation Loss: 4.6058\n",
      "Epoch: 558/1000 | Training Loss: 0.5980 | Validation Loss: 4.5617\n",
      "Epoch: 559/1000 | Training Loss: 0.5690 | Validation Loss: 4.6257\n",
      "Epoch: 560/1000 | Training Loss: 0.5693 | Validation Loss: 4.6522\n",
      "Epoch: 561/1000 | Training Loss: 0.5904 | Validation Loss: 4.6295\n",
      "Epoch: 562/1000 | Training Loss: 0.6103 | Validation Loss: 4.6158\n",
      "Epoch: 563/1000 | Training Loss: 0.5768 | Validation Loss: 4.6177\n",
      "Epoch: 564/1000 | Training Loss: 0.5612 | Validation Loss: 4.6045\n",
      "Epoch: 565/1000 | Training Loss: 0.5889 | Validation Loss: 4.6667\n",
      "Epoch: 566/1000 | Training Loss: 0.6050 | Validation Loss: 4.6498\n",
      "Epoch: 567/1000 | Training Loss: 0.6100 | Validation Loss: 4.5459\n",
      "Epoch: 568/1000 | Training Loss: 0.5774 | Validation Loss: 4.6104\n",
      "Epoch: 569/1000 | Training Loss: 0.5683 | Validation Loss: 4.6707\n",
      "Epoch: 570/1000 | Training Loss: 0.6018 | Validation Loss: 4.6413\n",
      "Epoch: 571/1000 | Training Loss: 0.6065 | Validation Loss: 4.6695\n",
      "Epoch: 572/1000 | Training Loss: 0.5981 | Validation Loss: 4.6092\n",
      "Epoch: 573/1000 | Training Loss: 0.5695 | Validation Loss: 4.6262\n",
      "Epoch: 574/1000 | Training Loss: 0.5972 | Validation Loss: 4.6889\n",
      "Epoch: 575/1000 | Training Loss: 0.6427 | Validation Loss: 4.6294\n",
      "Epoch: 576/1000 | Training Loss: 0.6285 | Validation Loss: 4.6456\n",
      "Epoch: 577/1000 | Training Loss: 0.5943 | Validation Loss: 4.6497\n",
      "Epoch: 578/1000 | Training Loss: 0.6184 | Validation Loss: 4.6595\n",
      "Epoch: 579/1000 | Training Loss: 0.6289 | Validation Loss: 4.7102\n",
      "Epoch: 580/1000 | Training Loss: 0.6103 | Validation Loss: 4.6055\n",
      "Epoch: 581/1000 | Training Loss: 0.5699 | Validation Loss: 4.6191\n",
      "Epoch: 582/1000 | Training Loss: 0.6030 | Validation Loss: 4.7590\n",
      "Epoch: 583/1000 | Training Loss: 0.6330 | Validation Loss: 4.6044\n",
      "Epoch: 584/1000 | Training Loss: 0.5971 | Validation Loss: 4.5464\n",
      "Epoch: 585/1000 | Training Loss: 0.5832 | Validation Loss: 4.7938\n",
      "Epoch: 586/1000 | Training Loss: 0.6179 | Validation Loss: 4.6341\n",
      "Epoch: 587/1000 | Training Loss: 0.5994 | Validation Loss: 4.6448\n",
      "Epoch: 588/1000 | Training Loss: 0.5931 | Validation Loss: 4.7980\n",
      "Epoch: 589/1000 | Training Loss: 0.6252 | Validation Loss: 4.6857\n",
      "Epoch: 590/1000 | Training Loss: 0.6480 | Validation Loss: 4.6571\n",
      "Epoch: 591/1000 | Training Loss: 0.6349 | Validation Loss: 4.8104\n",
      "Epoch: 592/1000 | Training Loss: 0.6442 | Validation Loss: 4.5784\n",
      "Epoch: 593/1000 | Training Loss: 0.6220 | Validation Loss: 4.6004\n",
      "Epoch: 594/1000 | Training Loss: 0.5908 | Validation Loss: 4.7828\n",
      "Epoch: 595/1000 | Training Loss: 0.6070 | Validation Loss: 4.7392\n",
      "Epoch: 596/1000 | Training Loss: 0.6117 | Validation Loss: 4.6382\n",
      "Epoch: 597/1000 | Training Loss: 0.5809 | Validation Loss: 4.6563\n",
      "Epoch: 598/1000 | Training Loss: 0.5990 | Validation Loss: 4.6625\n",
      "Epoch: 599/1000 | Training Loss: 0.6090 | Validation Loss: 4.7967\n",
      "Epoch: 600/1000 | Training Loss: 0.5914 | Validation Loss: 4.6654\n",
      "Epoch: 601/1000 | Training Loss: 0.5659 | Validation Loss: 4.6793\n",
      "Epoch: 602/1000 | Training Loss: 0.5930 | Validation Loss: 4.8148\n",
      "Epoch: 603/1000 | Training Loss: 0.6120 | Validation Loss: 4.6946\n",
      "Epoch: 604/1000 | Training Loss: 0.6095 | Validation Loss: 4.6997\n",
      "Epoch: 605/1000 | Training Loss: 0.6002 | Validation Loss: 4.8299\n",
      "Epoch: 606/1000 | Training Loss: 0.6168 | Validation Loss: 4.6690\n",
      "Epoch: 607/1000 | Training Loss: 0.6167 | Validation Loss: 4.7257\n",
      "Epoch: 608/1000 | Training Loss: 0.6171 | Validation Loss: 4.7626\n",
      "Epoch: 609/1000 | Training Loss: 0.5974 | Validation Loss: 4.7009\n",
      "Epoch: 610/1000 | Training Loss: 0.6041 | Validation Loss: 4.6812\n",
      "Epoch: 611/1000 | Training Loss: 0.5664 | Validation Loss: 4.7047\n",
      "Epoch: 612/1000 | Training Loss: 0.6013 | Validation Loss: 4.6919\n",
      "Epoch: 613/1000 | Training Loss: 0.6289 | Validation Loss: 4.7522\n",
      "Epoch: 614/1000 | Training Loss: 0.6198 | Validation Loss: 4.7824\n",
      "Epoch: 615/1000 | Training Loss: 0.6283 | Validation Loss: 4.7115\n",
      "Epoch: 616/1000 | Training Loss: 0.7070 | Validation Loss: 4.7665\n",
      "Epoch: 617/1000 | Training Loss: 0.6703 | Validation Loss: 4.8025\n",
      "Epoch: 618/1000 | Training Loss: 0.6568 | Validation Loss: 4.7337\n",
      "Epoch: 619/1000 | Training Loss: 0.6791 | Validation Loss: 4.8314\n",
      "Epoch: 620/1000 | Training Loss: 0.6530 | Validation Loss: 4.8533\n",
      "Epoch: 621/1000 | Training Loss: 0.6609 | Validation Loss: 4.6609\n",
      "Epoch: 622/1000 | Training Loss: 0.6581 | Validation Loss: 4.7106\n",
      "Epoch: 623/1000 | Training Loss: 0.6177 | Validation Loss: 4.8774\n",
      "Epoch: 624/1000 | Training Loss: 0.6527 | Validation Loss: 4.6805\n",
      "Epoch: 625/1000 | Training Loss: 0.6330 | Validation Loss: 4.6562\n",
      "Epoch: 626/1000 | Training Loss: 0.5968 | Validation Loss: 4.7073\n",
      "Epoch: 627/1000 | Training Loss: 0.6085 | Validation Loss: 4.7076\n",
      "Epoch: 628/1000 | Training Loss: 0.6095 | Validation Loss: 4.7335\n",
      "Epoch: 629/1000 | Training Loss: 0.6097 | Validation Loss: 4.7877\n",
      "Epoch: 630/1000 | Training Loss: 0.6224 | Validation Loss: 4.6326\n",
      "Epoch: 631/1000 | Training Loss: 0.6129 | Validation Loss: 4.5907\n",
      "Epoch: 632/1000 | Training Loss: 0.5817 | Validation Loss: 4.7544\n",
      "Epoch: 633/1000 | Training Loss: 0.6010 | Validation Loss: 4.7197\n",
      "Epoch: 634/1000 | Training Loss: 0.5710 | Validation Loss: 4.7313\n",
      "Epoch: 635/1000 | Training Loss: 0.5812 | Validation Loss: 4.7693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 636/1000 | Training Loss: 0.5766 | Validation Loss: 4.6743\n",
      "Epoch: 637/1000 | Training Loss: 0.5773 | Validation Loss: 4.6765\n",
      "Epoch: 638/1000 | Training Loss: 0.5753 | Validation Loss: 4.8044\n",
      "Epoch: 639/1000 | Training Loss: 0.5935 | Validation Loss: 4.7542\n",
      "Epoch: 640/1000 | Training Loss: 0.6137 | Validation Loss: 4.8018\n",
      "Epoch: 641/1000 | Training Loss: 0.6031 | Validation Loss: 4.7521\n",
      "Epoch: 642/1000 | Training Loss: 0.5780 | Validation Loss: 4.7101\n",
      "Epoch: 643/1000 | Training Loss: 0.5664 | Validation Loss: 4.8194\n",
      "Epoch: 644/1000 | Training Loss: 0.5695 | Validation Loss: 4.8028\n",
      "Epoch: 645/1000 | Training Loss: 0.5932 | Validation Loss: 4.7573\n",
      "Epoch: 646/1000 | Training Loss: 0.6065 | Validation Loss: 4.7476\n",
      "Epoch: 647/1000 | Training Loss: 0.5958 | Validation Loss: 4.8029\n",
      "Epoch: 648/1000 | Training Loss: 0.5891 | Validation Loss: 4.6774\n",
      "Epoch: 649/1000 | Training Loss: 0.5619 | Validation Loss: 4.7465\n",
      "Epoch: 650/1000 | Training Loss: 0.5530 | Validation Loss: 4.8192\n",
      "Epoch: 651/1000 | Training Loss: 0.5603 | Validation Loss: 4.7001\n",
      "Epoch: 652/1000 | Training Loss: 0.5797 | Validation Loss: 4.7218\n",
      "Epoch: 653/1000 | Training Loss: 0.5792 | Validation Loss: 4.7463\n",
      "Epoch: 654/1000 | Training Loss: 0.5661 | Validation Loss: 4.7353\n",
      "Epoch: 655/1000 | Training Loss: 0.5563 | Validation Loss: 4.7595\n",
      "Epoch: 656/1000 | Training Loss: 0.5495 | Validation Loss: 4.7919\n",
      "Epoch: 657/1000 | Training Loss: 0.5473 | Validation Loss: 4.7742\n",
      "Epoch: 658/1000 | Training Loss: 0.5591 | Validation Loss: 4.7461\n",
      "Epoch: 659/1000 | Training Loss: 0.5681 | Validation Loss: 4.7895\n",
      "Epoch: 660/1000 | Training Loss: 0.5653 | Validation Loss: 4.7761\n",
      "Epoch: 661/1000 | Training Loss: 0.5464 | Validation Loss: 4.7673\n",
      "Epoch: 662/1000 | Training Loss: 0.5362 | Validation Loss: 4.7932\n",
      "Epoch: 663/1000 | Training Loss: 0.5403 | Validation Loss: 4.8321\n",
      "Epoch: 664/1000 | Training Loss: 0.5579 | Validation Loss: 4.8329\n",
      "Epoch: 665/1000 | Training Loss: 0.5659 | Validation Loss: 4.7758\n",
      "Epoch: 666/1000 | Training Loss: 0.5526 | Validation Loss: 4.7800\n",
      "Epoch: 667/1000 | Training Loss: 0.5419 | Validation Loss: 4.8287\n",
      "Epoch: 668/1000 | Training Loss: 0.5410 | Validation Loss: 4.8198\n",
      "Epoch: 669/1000 | Training Loss: 0.5684 | Validation Loss: 4.9344\n",
      "Epoch: 670/1000 | Training Loss: 0.6293 | Validation Loss: 4.8855\n",
      "Epoch: 671/1000 | Training Loss: 0.6381 | Validation Loss: 4.7831\n",
      "Epoch: 672/1000 | Training Loss: 0.6056 | Validation Loss: 4.8484\n",
      "Epoch: 673/1000 | Training Loss: 0.5498 | Validation Loss: 4.8687\n",
      "Epoch: 674/1000 | Training Loss: 0.5665 | Validation Loss: 4.8852\n",
      "Epoch: 675/1000 | Training Loss: 0.6443 | Validation Loss: 4.8703\n",
      "Epoch: 676/1000 | Training Loss: 0.6085 | Validation Loss: 4.8031\n",
      "Epoch: 677/1000 | Training Loss: 0.5673 | Validation Loss: 4.7469\n",
      "Epoch: 678/1000 | Training Loss: 0.5480 | Validation Loss: 4.8465\n",
      "Epoch: 679/1000 | Training Loss: 0.5717 | Validation Loss: 4.8867\n",
      "Epoch: 680/1000 | Training Loss: 0.5879 | Validation Loss: 4.7790\n",
      "Epoch: 681/1000 | Training Loss: 0.5617 | Validation Loss: 4.8335\n",
      "Epoch: 682/1000 | Training Loss: 0.5543 | Validation Loss: 4.7963\n",
      "Epoch: 683/1000 | Training Loss: 0.5467 | Validation Loss: 4.8178\n",
      "Epoch: 684/1000 | Training Loss: 0.5449 | Validation Loss: 4.8553\n",
      "Epoch: 685/1000 | Training Loss: 0.5710 | Validation Loss: 4.8331\n",
      "Epoch: 686/1000 | Training Loss: 0.5797 | Validation Loss: 4.9054\n",
      "Epoch: 687/1000 | Training Loss: 0.5731 | Validation Loss: 4.8397\n",
      "Epoch: 688/1000 | Training Loss: 0.5734 | Validation Loss: 4.8769\n",
      "Epoch: 689/1000 | Training Loss: 0.5903 | Validation Loss: 4.8591\n",
      "Epoch: 690/1000 | Training Loss: 0.5810 | Validation Loss: 4.8570\n",
      "Epoch: 691/1000 | Training Loss: 0.5817 | Validation Loss: 4.8792\n",
      "Epoch: 692/1000 | Training Loss: 0.5770 | Validation Loss: 4.9105\n",
      "Epoch: 693/1000 | Training Loss: 0.5511 | Validation Loss: 4.8632\n",
      "Epoch: 694/1000 | Training Loss: 0.5500 | Validation Loss: 4.8807\n",
      "Epoch: 695/1000 | Training Loss: 0.5573 | Validation Loss: 4.8798\n",
      "Epoch: 696/1000 | Training Loss: 0.5584 | Validation Loss: 4.8125\n",
      "Epoch: 697/1000 | Training Loss: 0.5548 | Validation Loss: 4.8985\n",
      "Epoch: 698/1000 | Training Loss: 0.5659 | Validation Loss: 4.8559\n",
      "Epoch: 699/1000 | Training Loss: 0.5707 | Validation Loss: 4.9047\n",
      "Epoch: 700/1000 | Training Loss: 0.5544 | Validation Loss: 4.8732\n",
      "Epoch: 701/1000 | Training Loss: 0.5612 | Validation Loss: 4.9067\n",
      "Epoch: 702/1000 | Training Loss: 0.6078 | Validation Loss: 4.8561\n",
      "Epoch: 703/1000 | Training Loss: 0.6201 | Validation Loss: 4.8894\n",
      "Epoch: 704/1000 | Training Loss: 0.5919 | Validation Loss: 4.8718\n",
      "Epoch: 705/1000 | Training Loss: 0.5596 | Validation Loss: 4.8960\n",
      "Epoch: 706/1000 | Training Loss: 0.5534 | Validation Loss: 4.8899\n",
      "Epoch: 707/1000 | Training Loss: 0.5838 | Validation Loss: 4.8953\n",
      "Epoch: 708/1000 | Training Loss: 0.6106 | Validation Loss: 4.9603\n",
      "Epoch: 709/1000 | Training Loss: 0.6106 | Validation Loss: 4.8061\n",
      "Epoch: 710/1000 | Training Loss: 0.5546 | Validation Loss: 4.8695\n",
      "Epoch: 711/1000 | Training Loss: 0.5490 | Validation Loss: 4.9519\n",
      "Epoch: 712/1000 | Training Loss: 0.6034 | Validation Loss: 4.8651\n",
      "Epoch: 713/1000 | Training Loss: 0.5997 | Validation Loss: 4.8821\n",
      "Epoch: 714/1000 | Training Loss: 0.5819 | Validation Loss: 4.8730\n",
      "Epoch: 715/1000 | Training Loss: 0.5520 | Validation Loss: 4.8475\n",
      "Epoch: 716/1000 | Training Loss: 0.5505 | Validation Loss: 4.9572\n",
      "Epoch: 717/1000 | Training Loss: 0.5797 | Validation Loss: 4.8989\n",
      "Epoch: 718/1000 | Training Loss: 0.5740 | Validation Loss: 4.8439\n",
      "Epoch: 719/1000 | Training Loss: 0.5614 | Validation Loss: 4.8819\n",
      "Epoch: 720/1000 | Training Loss: 0.5507 | Validation Loss: 4.8336\n",
      "Epoch: 721/1000 | Training Loss: 0.5539 | Validation Loss: 4.9663\n",
      "Epoch: 722/1000 | Training Loss: 0.5750 | Validation Loss: 4.9487\n",
      "Epoch: 723/1000 | Training Loss: 0.5813 | Validation Loss: 4.8680\n",
      "Epoch: 724/1000 | Training Loss: 0.5911 | Validation Loss: 4.9358\n",
      "Epoch: 725/1000 | Training Loss: 0.5658 | Validation Loss: 4.9151\n",
      "Epoch: 726/1000 | Training Loss: 0.5469 | Validation Loss: 4.9103\n",
      "Epoch: 727/1000 | Training Loss: 0.5553 | Validation Loss: 4.9675\n",
      "Epoch: 728/1000 | Training Loss: 0.5788 | Validation Loss: 4.9319\n",
      "Epoch: 729/1000 | Training Loss: 0.5688 | Validation Loss: 4.8932\n",
      "Epoch: 730/1000 | Training Loss: 0.5583 | Validation Loss: 4.9776\n",
      "Epoch: 731/1000 | Training Loss: 0.5398 | Validation Loss: 4.8794\n",
      "Epoch: 732/1000 | Training Loss: 0.5336 | Validation Loss: 4.9331\n",
      "Epoch: 733/1000 | Training Loss: 0.5553 | Validation Loss: 4.9865\n",
      "Epoch: 734/1000 | Training Loss: 0.5715 | Validation Loss: 4.9339\n",
      "Epoch: 735/1000 | Training Loss: 0.5673 | Validation Loss: 4.9170\n",
      "Epoch: 736/1000 | Training Loss: 0.5334 | Validation Loss: 4.8974\n",
      "Epoch: 737/1000 | Training Loss: 0.5429 | Validation Loss: 4.9536\n",
      "Epoch: 738/1000 | Training Loss: 0.5792 | Validation Loss: 4.9800\n",
      "Epoch: 739/1000 | Training Loss: 0.6175 | Validation Loss: 4.9812\n",
      "Epoch: 740/1000 | Training Loss: 0.5994 | Validation Loss: 4.9315\n",
      "Epoch: 741/1000 | Training Loss: 0.5669 | Validation Loss: 4.8805\n",
      "Epoch: 742/1000 | Training Loss: 0.5532 | Validation Loss: 5.0144\n",
      "Epoch: 743/1000 | Training Loss: 0.6020 | Validation Loss: 4.9782\n",
      "Epoch: 744/1000 | Training Loss: 0.6231 | Validation Loss: 4.9563\n",
      "Epoch: 745/1000 | Training Loss: 0.5735 | Validation Loss: 4.9068\n",
      "Epoch: 746/1000 | Training Loss: 0.5518 | Validation Loss: 4.9169\n",
      "Epoch: 747/1000 | Training Loss: 0.5806 | Validation Loss: 5.0379\n",
      "Epoch: 748/1000 | Training Loss: 0.5915 | Validation Loss: 4.9590\n",
      "Epoch: 749/1000 | Training Loss: 0.5799 | Validation Loss: 4.8910\n",
      "Epoch: 750/1000 | Training Loss: 0.5574 | Validation Loss: 4.9781\n",
      "Epoch: 751/1000 | Training Loss: 0.5547 | Validation Loss: 4.9424\n",
      "Epoch: 752/1000 | Training Loss: 0.5771 | Validation Loss: 4.9250\n",
      "Epoch: 753/1000 | Training Loss: 0.5626 | Validation Loss: 4.9886\n",
      "Epoch: 754/1000 | Training Loss: 0.5497 | Validation Loss: 4.9311\n",
      "Epoch: 755/1000 | Training Loss: 0.5495 | Validation Loss: 4.9503\n",
      "Epoch: 756/1000 | Training Loss: 0.5677 | Validation Loss: 5.0236\n",
      "Epoch: 757/1000 | Training Loss: 0.5958 | Validation Loss: 4.8707\n",
      "Epoch: 758/1000 | Training Loss: 0.5595 | Validation Loss: 4.9066\n",
      "Epoch: 759/1000 | Training Loss: 0.5506 | Validation Loss: 4.9404\n",
      "Epoch: 760/1000 | Training Loss: 0.5701 | Validation Loss: 4.9756\n",
      "Epoch: 761/1000 | Training Loss: 0.5664 | Validation Loss: 4.9436\n",
      "Epoch: 762/1000 | Training Loss: 0.5454 | Validation Loss: 4.9432\n",
      "Epoch: 763/1000 | Training Loss: 0.5298 | Validation Loss: 4.9711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 764/1000 | Training Loss: 0.5329 | Validation Loss: 4.9600\n",
      "Epoch: 765/1000 | Training Loss: 0.5495 | Validation Loss: 4.9845\n",
      "Epoch: 766/1000 | Training Loss: 0.5332 | Validation Loss: 4.9656\n",
      "Epoch: 767/1000 | Training Loss: 0.5354 | Validation Loss: 4.9590\n",
      "Epoch: 768/1000 | Training Loss: 0.5222 | Validation Loss: 5.0228\n",
      "Epoch: 769/1000 | Training Loss: 0.5361 | Validation Loss: 4.9672\n",
      "Epoch: 770/1000 | Training Loss: 0.5459 | Validation Loss: 5.0572\n",
      "Epoch: 771/1000 | Training Loss: 0.5596 | Validation Loss: 5.0196\n",
      "Epoch: 772/1000 | Training Loss: 0.5751 | Validation Loss: 5.0511\n",
      "Epoch: 773/1000 | Training Loss: 0.5955 | Validation Loss: 5.1002\n",
      "Epoch: 774/1000 | Training Loss: 0.5728 | Validation Loss: 5.0337\n",
      "Epoch: 775/1000 | Training Loss: 0.5507 | Validation Loss: 5.0062\n",
      "Epoch: 776/1000 | Training Loss: 0.5342 | Validation Loss: 5.0245\n",
      "Epoch: 777/1000 | Training Loss: 0.5489 | Validation Loss: 4.9474\n",
      "Epoch: 778/1000 | Training Loss: 0.5402 | Validation Loss: 4.9682\n",
      "Epoch: 779/1000 | Training Loss: 0.5371 | Validation Loss: 5.0182\n",
      "Epoch: 780/1000 | Training Loss: 0.5519 | Validation Loss: 4.9985\n",
      "Epoch: 781/1000 | Training Loss: 0.5565 | Validation Loss: 5.0030\n",
      "Epoch: 782/1000 | Training Loss: 0.5507 | Validation Loss: 4.9933\n",
      "Epoch: 783/1000 | Training Loss: 0.5368 | Validation Loss: 5.0322\n",
      "Epoch: 784/1000 | Training Loss: 0.5399 | Validation Loss: 5.0895\n",
      "Epoch: 785/1000 | Training Loss: 0.5596 | Validation Loss: 5.0608\n",
      "Epoch: 786/1000 | Training Loss: 0.6052 | Validation Loss: 5.2121\n",
      "Epoch: 787/1000 | Training Loss: 0.6330 | Validation Loss: 5.0215\n",
      "Epoch: 788/1000 | Training Loss: 0.5511 | Validation Loss: 5.0344\n",
      "Epoch: 789/1000 | Training Loss: 0.5584 | Validation Loss: 5.2517\n",
      "Epoch: 790/1000 | Training Loss: 0.6261 | Validation Loss: 5.0534\n",
      "Epoch: 791/1000 | Training Loss: 0.5822 | Validation Loss: 5.0025\n",
      "Epoch: 792/1000 | Training Loss: 0.5782 | Validation Loss: 5.1047\n",
      "Epoch: 793/1000 | Training Loss: 0.5998 | Validation Loss: 4.9678\n",
      "Epoch: 794/1000 | Training Loss: 0.5673 | Validation Loss: 5.0705\n",
      "Epoch: 795/1000 | Training Loss: 0.5692 | Validation Loss: 5.1424\n",
      "Epoch: 796/1000 | Training Loss: 0.5639 | Validation Loss: 5.0119\n",
      "Epoch: 797/1000 | Training Loss: 0.5526 | Validation Loss: 5.0400\n",
      "Epoch: 798/1000 | Training Loss: 0.5453 | Validation Loss: 5.0320\n",
      "Epoch: 799/1000 | Training Loss: 0.5375 | Validation Loss: 4.9857\n",
      "Epoch: 800/1000 | Training Loss: 0.5382 | Validation Loss: 5.1003\n",
      "Epoch: 801/1000 | Training Loss: 0.5485 | Validation Loss: 5.0880\n",
      "Epoch: 802/1000 | Training Loss: 0.5567 | Validation Loss: 5.0353\n",
      "Epoch: 803/1000 | Training Loss: 0.5517 | Validation Loss: 5.1273\n",
      "Epoch: 804/1000 | Training Loss: 0.5525 | Validation Loss: 5.0200\n",
      "Epoch: 805/1000 | Training Loss: 0.5276 | Validation Loss: 5.0086\n",
      "Epoch: 806/1000 | Training Loss: 0.5149 | Validation Loss: 5.0785\n",
      "Epoch: 807/1000 | Training Loss: 0.5251 | Validation Loss: 5.0325\n",
      "Epoch: 808/1000 | Training Loss: 0.5383 | Validation Loss: 5.0795\n",
      "Epoch: 809/1000 | Training Loss: 0.5477 | Validation Loss: 5.0769\n",
      "Epoch: 810/1000 | Training Loss: 0.5877 | Validation Loss: 5.0772\n",
      "Epoch: 811/1000 | Training Loss: 0.5829 | Validation Loss: 5.1179\n",
      "Epoch: 812/1000 | Training Loss: 0.5449 | Validation Loss: 5.0765\n",
      "Epoch: 813/1000 | Training Loss: 0.5215 | Validation Loss: 5.0395\n",
      "Epoch: 814/1000 | Training Loss: 0.5247 | Validation Loss: 5.0587\n",
      "Epoch: 815/1000 | Training Loss: 0.5348 | Validation Loss: 5.1286\n",
      "Epoch: 816/1000 | Training Loss: 0.5374 | Validation Loss: 5.0447\n",
      "Epoch: 817/1000 | Training Loss: 0.5313 | Validation Loss: 5.0615\n",
      "Epoch: 818/1000 | Training Loss: 0.5229 | Validation Loss: 5.0859\n",
      "Epoch: 819/1000 | Training Loss: 0.5250 | Validation Loss: 5.0485\n",
      "Epoch: 820/1000 | Training Loss: 0.5314 | Validation Loss: 5.1245\n",
      "Epoch: 821/1000 | Training Loss: 0.5208 | Validation Loss: 5.0790\n",
      "Epoch: 822/1000 | Training Loss: 0.5072 | Validation Loss: 5.0724\n",
      "Epoch: 823/1000 | Training Loss: 0.5065 | Validation Loss: 5.0800\n",
      "Epoch: 824/1000 | Training Loss: 0.5119 | Validation Loss: 5.0796\n",
      "Epoch: 825/1000 | Training Loss: 0.5162 | Validation Loss: 5.1182\n",
      "Epoch: 826/1000 | Training Loss: 0.5197 | Validation Loss: 5.1000\n",
      "Epoch: 827/1000 | Training Loss: 0.5184 | Validation Loss: 5.1400\n",
      "Epoch: 828/1000 | Training Loss: 0.5141 | Validation Loss: 5.1494\n",
      "Epoch: 829/1000 | Training Loss: 0.5059 | Validation Loss: 5.1267\n",
      "Epoch: 830/1000 | Training Loss: 0.5183 | Validation Loss: 5.1789\n",
      "Epoch: 831/1000 | Training Loss: 0.5614 | Validation Loss: 5.1263\n",
      "Epoch: 832/1000 | Training Loss: 0.5896 | Validation Loss: 5.1455\n",
      "Epoch: 833/1000 | Training Loss: 0.5519 | Validation Loss: 5.1357\n",
      "Epoch: 834/1000 | Training Loss: 0.5214 | Validation Loss: 5.0726\n",
      "Epoch: 835/1000 | Training Loss: 0.5232 | Validation Loss: 5.2191\n",
      "Epoch: 836/1000 | Training Loss: 0.5370 | Validation Loss: 5.1235\n",
      "Epoch: 837/1000 | Training Loss: 0.5420 | Validation Loss: 5.0728\n",
      "Epoch: 838/1000 | Training Loss: 0.5372 | Validation Loss: 5.1464\n",
      "Epoch: 839/1000 | Training Loss: 0.5262 | Validation Loss: 5.0913\n",
      "Epoch: 840/1000 | Training Loss: 0.5119 | Validation Loss: 5.1739\n",
      "Epoch: 841/1000 | Training Loss: 0.5153 | Validation Loss: 5.1272\n",
      "Epoch: 842/1000 | Training Loss: 0.5228 | Validation Loss: 5.1370\n",
      "Epoch: 843/1000 | Training Loss: 0.5313 | Validation Loss: 5.1237\n",
      "Epoch: 844/1000 | Training Loss: 0.5329 | Validation Loss: 5.1164\n",
      "Epoch: 845/1000 | Training Loss: 0.5101 | Validation Loss: 5.1145\n",
      "Epoch: 846/1000 | Training Loss: 0.5005 | Validation Loss: 5.1321\n",
      "Epoch: 847/1000 | Training Loss: 0.5082 | Validation Loss: 5.1658\n",
      "Epoch: 848/1000 | Training Loss: 0.5163 | Validation Loss: 5.1701\n",
      "Epoch: 849/1000 | Training Loss: 0.5233 | Validation Loss: 5.1411\n",
      "Epoch: 850/1000 | Training Loss: 0.5205 | Validation Loss: 5.1429\n",
      "Epoch: 851/1000 | Training Loss: 0.5246 | Validation Loss: 5.2712\n",
      "Epoch: 852/1000 | Training Loss: 0.5613 | Validation Loss: 5.1537\n",
      "Epoch: 853/1000 | Training Loss: 0.5960 | Validation Loss: 5.2014\n",
      "Epoch: 854/1000 | Training Loss: 0.5739 | Validation Loss: 5.2229\n",
      "Epoch: 855/1000 | Training Loss: 0.5274 | Validation Loss: 5.1540\n",
      "Epoch: 856/1000 | Training Loss: 0.5442 | Validation Loss: 5.3712\n",
      "Epoch: 857/1000 | Training Loss: 0.5784 | Validation Loss: 5.2323\n",
      "Epoch: 858/1000 | Training Loss: 0.5632 | Validation Loss: 5.1105\n",
      "Epoch: 859/1000 | Training Loss: 0.5851 | Validation Loss: 5.3301\n",
      "Epoch: 860/1000 | Training Loss: 0.6119 | Validation Loss: 5.1795\n",
      "Epoch: 861/1000 | Training Loss: 0.5604 | Validation Loss: 5.2114\n",
      "Epoch: 862/1000 | Training Loss: 0.5236 | Validation Loss: 5.2985\n",
      "Epoch: 863/1000 | Training Loss: 0.5605 | Validation Loss: 5.1079\n",
      "Epoch: 864/1000 | Training Loss: 0.5716 | Validation Loss: 5.2691\n",
      "Epoch: 865/1000 | Training Loss: 0.5404 | Validation Loss: 5.2310\n",
      "Epoch: 866/1000 | Training Loss: 0.5265 | Validation Loss: 5.1550\n",
      "Epoch: 867/1000 | Training Loss: 0.5262 | Validation Loss: 5.2066\n",
      "Epoch: 868/1000 | Training Loss: 0.5325 | Validation Loss: 5.1813\n",
      "Epoch: 869/1000 | Training Loss: 0.5245 | Validation Loss: 5.2138\n",
      "Epoch: 870/1000 | Training Loss: 0.5389 | Validation Loss: 5.3003\n",
      "Epoch: 871/1000 | Training Loss: 0.5337 | Validation Loss: 5.1697\n",
      "Epoch: 872/1000 | Training Loss: 0.5075 | Validation Loss: 5.1558\n",
      "Epoch: 873/1000 | Training Loss: 0.5122 | Validation Loss: 5.2975\n",
      "Epoch: 874/1000 | Training Loss: 0.5350 | Validation Loss: 5.2756\n",
      "Epoch: 875/1000 | Training Loss: 0.5401 | Validation Loss: 5.2552\n",
      "Epoch: 876/1000 | Training Loss: 0.5200 | Validation Loss: 5.2614\n",
      "Epoch: 877/1000 | Training Loss: 0.5425 | Validation Loss: 5.2139\n",
      "Epoch: 878/1000 | Training Loss: 0.5824 | Validation Loss: 5.3319\n",
      "Epoch: 879/1000 | Training Loss: 0.6096 | Validation Loss: 5.3178\n",
      "Epoch: 880/1000 | Training Loss: 0.5523 | Validation Loss: 5.1700\n",
      "Epoch: 881/1000 | Training Loss: 0.5257 | Validation Loss: 5.2319\n",
      "Epoch: 882/1000 | Training Loss: 0.5234 | Validation Loss: 5.2879\n",
      "Epoch: 883/1000 | Training Loss: 0.5555 | Validation Loss: 5.2117\n",
      "Epoch: 884/1000 | Training Loss: 0.5729 | Validation Loss: 5.3022\n",
      "Epoch: 885/1000 | Training Loss: 0.5372 | Validation Loss: 5.2034\n",
      "Epoch: 886/1000 | Training Loss: 0.5190 | Validation Loss: 5.2582\n",
      "Epoch: 887/1000 | Training Loss: 0.5459 | Validation Loss: 5.3439\n",
      "Epoch: 888/1000 | Training Loss: 0.5395 | Validation Loss: 5.1965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 889/1000 | Training Loss: 0.5163 | Validation Loss: 5.2096\n",
      "Epoch: 890/1000 | Training Loss: 0.5172 | Validation Loss: 5.2687\n",
      "Epoch: 891/1000 | Training Loss: 0.5276 | Validation Loss: 5.2651\n",
      "Epoch: 892/1000 | Training Loss: 0.5292 | Validation Loss: 5.2510\n",
      "Epoch: 893/1000 | Training Loss: 0.5332 | Validation Loss: 5.1966\n",
      "Epoch: 894/1000 | Training Loss: 0.5217 | Validation Loss: 5.2667\n",
      "Epoch: 895/1000 | Training Loss: 0.5126 | Validation Loss: 5.2496\n",
      "Epoch: 896/1000 | Training Loss: 0.5111 | Validation Loss: 5.2605\n",
      "Epoch: 897/1000 | Training Loss: 0.5230 | Validation Loss: 5.3157\n",
      "Epoch: 898/1000 | Training Loss: 0.5186 | Validation Loss: 5.1698\n",
      "Epoch: 899/1000 | Training Loss: 0.5167 | Validation Loss: 5.3261\n",
      "Epoch: 900/1000 | Training Loss: 0.5116 | Validation Loss: 5.2316\n",
      "Epoch: 901/1000 | Training Loss: 0.5004 | Validation Loss: 5.2289\n",
      "Epoch: 902/1000 | Training Loss: 0.4950 | Validation Loss: 5.3421\n",
      "Epoch: 903/1000 | Training Loss: 0.5004 | Validation Loss: 5.2466\n",
      "Epoch: 904/1000 | Training Loss: 0.5070 | Validation Loss: 5.2990\n",
      "Epoch: 905/1000 | Training Loss: 0.5109 | Validation Loss: 5.3149\n",
      "Epoch: 906/1000 | Training Loss: 0.5313 | Validation Loss: 5.3001\n",
      "Epoch: 907/1000 | Training Loss: 0.5240 | Validation Loss: 5.2779\n",
      "Epoch: 908/1000 | Training Loss: 0.5054 | Validation Loss: 5.3170\n",
      "Epoch: 909/1000 | Training Loss: 0.4973 | Validation Loss: 5.2979\n",
      "Epoch: 910/1000 | Training Loss: 0.4961 | Validation Loss: 5.3114\n",
      "Epoch: 911/1000 | Training Loss: 0.4977 | Validation Loss: 5.2889\n",
      "Epoch: 912/1000 | Training Loss: 0.4917 | Validation Loss: 5.2615\n",
      "Epoch: 913/1000 | Training Loss: 0.5007 | Validation Loss: 5.3343\n",
      "Epoch: 914/1000 | Training Loss: 0.5017 | Validation Loss: 5.2787\n",
      "Epoch: 915/1000 | Training Loss: 0.5043 | Validation Loss: 5.3222\n",
      "Epoch: 916/1000 | Training Loss: 0.5193 | Validation Loss: 5.3405\n",
      "Epoch: 917/1000 | Training Loss: 0.5554 | Validation Loss: 5.4524\n",
      "Epoch: 918/1000 | Training Loss: 0.6345 | Validation Loss: 5.4314\n",
      "Epoch: 919/1000 | Training Loss: 0.6417 | Validation Loss: 5.2889\n",
      "Epoch: 920/1000 | Training Loss: 0.5837 | Validation Loss: 5.3394\n",
      "Epoch: 921/1000 | Training Loss: 0.5279 | Validation Loss: 5.3334\n",
      "Epoch: 922/1000 | Training Loss: 0.5267 | Validation Loss: 5.3574\n",
      "Epoch: 923/1000 | Training Loss: 0.5514 | Validation Loss: 5.3182\n",
      "Epoch: 924/1000 | Training Loss: 0.5237 | Validation Loss: 5.2822\n",
      "Epoch: 925/1000 | Training Loss: 0.5273 | Validation Loss: 5.3452\n",
      "Epoch: 926/1000 | Training Loss: 0.5163 | Validation Loss: 5.3036\n",
      "Epoch: 927/1000 | Training Loss: 0.5311 | Validation Loss: 5.3980\n",
      "Epoch: 928/1000 | Training Loss: 0.5398 | Validation Loss: 5.3812\n",
      "Epoch: 929/1000 | Training Loss: 0.5305 | Validation Loss: 5.3147\n",
      "Epoch: 930/1000 | Training Loss: 0.5223 | Validation Loss: 5.4160\n",
      "Epoch: 931/1000 | Training Loss: 0.5226 | Validation Loss: 5.3548\n",
      "Epoch: 932/1000 | Training Loss: 0.5475 | Validation Loss: 5.3540\n",
      "Epoch: 933/1000 | Training Loss: 0.5763 | Validation Loss: 5.3963\n",
      "Epoch: 934/1000 | Training Loss: 0.5503 | Validation Loss: 5.3516\n",
      "Epoch: 935/1000 | Training Loss: 0.4982 | Validation Loss: 5.3407\n",
      "Epoch: 936/1000 | Training Loss: 0.5125 | Validation Loss: 5.3926\n",
      "Epoch: 937/1000 | Training Loss: 0.5498 | Validation Loss: 5.3683\n",
      "Epoch: 938/1000 | Training Loss: 0.5398 | Validation Loss: 5.2839\n",
      "Epoch: 939/1000 | Training Loss: 0.5244 | Validation Loss: 5.4737\n",
      "Epoch: 940/1000 | Training Loss: 0.5278 | Validation Loss: 5.3500\n",
      "Epoch: 941/1000 | Training Loss: 0.5440 | Validation Loss: 5.3653\n",
      "Epoch: 942/1000 | Training Loss: 0.5197 | Validation Loss: 5.4748\n",
      "Epoch: 943/1000 | Training Loss: 0.5152 | Validation Loss: 5.3391\n",
      "Epoch: 944/1000 | Training Loss: 0.5431 | Validation Loss: 5.5485\n",
      "Epoch: 945/1000 | Training Loss: 0.5655 | Validation Loss: 5.4311\n",
      "Epoch: 946/1000 | Training Loss: 0.5022 | Validation Loss: 5.3606\n",
      "Epoch: 947/1000 | Training Loss: 0.5246 | Validation Loss: 5.4608\n",
      "Epoch: 948/1000 | Training Loss: 0.5567 | Validation Loss: 5.3053\n",
      "Epoch: 949/1000 | Training Loss: 0.5211 | Validation Loss: 5.4632\n",
      "Epoch: 950/1000 | Training Loss: 0.5226 | Validation Loss: 5.4883\n",
      "Epoch: 951/1000 | Training Loss: 0.5572 | Validation Loss: 5.3624\n",
      "Epoch: 952/1000 | Training Loss: 0.5630 | Validation Loss: 5.4209\n",
      "Epoch: 953/1000 | Training Loss: 0.5312 | Validation Loss: 5.4630\n",
      "Epoch: 954/1000 | Training Loss: 0.5453 | Validation Loss: 5.4308\n",
      "Epoch: 955/1000 | Training Loss: 0.5536 | Validation Loss: 5.5243\n",
      "Epoch: 956/1000 | Training Loss: 0.5528 | Validation Loss: 5.3491\n",
      "Epoch: 957/1000 | Training Loss: 0.5221 | Validation Loss: 5.3276\n",
      "Epoch: 958/1000 | Training Loss: 0.5532 | Validation Loss: 5.5952\n",
      "Epoch: 959/1000 | Training Loss: 0.5514 | Validation Loss: 5.4325\n",
      "Epoch: 960/1000 | Training Loss: 0.5869 | Validation Loss: 5.3845\n",
      "Epoch: 961/1000 | Training Loss: 0.5928 | Validation Loss: 5.4925\n",
      "Epoch: 962/1000 | Training Loss: 0.5994 | Validation Loss: 5.4846\n",
      "Epoch: 963/1000 | Training Loss: 0.5889 | Validation Loss: 5.5177\n",
      "Epoch: 964/1000 | Training Loss: 0.5492 | Validation Loss: 5.4754\n",
      "Epoch: 965/1000 | Training Loss: 0.5256 | Validation Loss: 5.4042\n",
      "Epoch: 966/1000 | Training Loss: 0.5673 | Validation Loss: 5.4634\n",
      "Epoch: 967/1000 | Training Loss: 0.6017 | Validation Loss: 5.3298\n",
      "Epoch: 968/1000 | Training Loss: 0.5202 | Validation Loss: 5.4491\n",
      "Epoch: 969/1000 | Training Loss: 0.5918 | Validation Loss: 5.5851\n",
      "Epoch: 970/1000 | Training Loss: 0.6011 | Validation Loss: 5.3473\n",
      "Epoch: 971/1000 | Training Loss: 0.6000 | Validation Loss: 5.4230\n",
      "Epoch: 972/1000 | Training Loss: 0.5596 | Validation Loss: 5.6639\n",
      "Epoch: 973/1000 | Training Loss: 0.6399 | Validation Loss: 5.4916\n",
      "Epoch: 974/1000 | Training Loss: 0.6809 | Validation Loss: 5.7176\n",
      "Epoch: 975/1000 | Training Loss: 0.6847 | Validation Loss: 5.7124\n",
      "Epoch: 976/1000 | Training Loss: 0.7335 | Validation Loss: 5.3552\n",
      "Epoch: 977/1000 | Training Loss: 0.5907 | Validation Loss: 5.5553\n",
      "Epoch: 978/1000 | Training Loss: 0.6138 | Validation Loss: 5.6177\n",
      "Epoch: 979/1000 | Training Loss: 0.6693 | Validation Loss: 5.4468\n",
      "Epoch: 980/1000 | Training Loss: 0.6701 | Validation Loss: 5.1336\n",
      "Epoch: 981/1000 | Training Loss: 0.6366 | Validation Loss: 5.3552\n",
      "Epoch: 982/1000 | Training Loss: 0.5907 | Validation Loss: 5.5832\n",
      "Epoch: 983/1000 | Training Loss: 0.6276 | Validation Loss: 5.5310\n",
      "Epoch: 984/1000 | Training Loss: 0.5853 | Validation Loss: 5.5156\n",
      "Epoch: 985/1000 | Training Loss: 0.5845 | Validation Loss: 5.3863\n",
      "Epoch: 986/1000 | Training Loss: 0.5987 | Validation Loss: 5.3397\n",
      "Epoch: 987/1000 | Training Loss: 0.5828 | Validation Loss: 5.4018\n",
      "Epoch: 988/1000 | Training Loss: 0.5819 | Validation Loss: 5.4556\n",
      "Epoch: 989/1000 | Training Loss: 0.5613 | Validation Loss: 5.4011\n",
      "Epoch: 990/1000 | Training Loss: 0.5339 | Validation Loss: 5.3316\n",
      "Epoch: 991/1000 | Training Loss: 0.5524 | Validation Loss: 5.2903\n",
      "Epoch: 992/1000 | Training Loss: 0.5329 | Validation Loss: 5.4632\n",
      "Epoch: 993/1000 | Training Loss: 0.5179 | Validation Loss: 5.5514\n",
      "Epoch: 994/1000 | Training Loss: 0.5258 | Validation Loss: 5.4028\n",
      "Epoch: 995/1000 | Training Loss: 0.5302 | Validation Loss: 5.4488\n",
      "Epoch: 996/1000 | Training Loss: 0.5194 | Validation Loss: 5.4770\n",
      "Epoch: 997/1000 | Training Loss: 0.5076 | Validation Loss: 5.4250\n",
      "Epoch: 998/1000 | Training Loss: 0.5118 | Validation Loss: 5.4935\n",
      "Epoch: 999/1000 | Training Loss: 0.5133 | Validation Loss: 5.3854\n",
      "Epoch: 1000/1000 | Training Loss: 0.5174 | Validation Loss: 5.3358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "for epoch in range(1000):\n",
    "    loss = train_model(model, optimizer, criterion, X_train, Y_train)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, Y_val).item()\n",
    "        if val_loss < best_val_loss:\n",
    "            best_model = model\n",
    "            best_val_loss = val_loss\n",
    "    print(f'Epoch: {epoch+1}/1000 | Training Loss: {loss:.4f} | Validation Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0436971187591553"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'model_state_dict': best_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"./sgg_ckpt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SceneGraph import SceneGraph\n",
    "import torch\n",
    "\n",
    "class SGGInference:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = SceneGraph(16, 2318)\n",
    "        checkpoint = torch.load(model_path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    def infer(self, X):\n",
    "        print(self.model(X).shape)\n",
    "        return torch.argmax(self.model(X), dim=1).item()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
